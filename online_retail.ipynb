{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Project: Online Retail EDA with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project explores an **online retail transactions dataset**, focusing on **data cleaning, exploratory data analysis (EDA), and deriving business insights**. The dataset contains information about customer purchases, including invoice details, product descriptions, quantities, prices, and customer IDs. \n",
    "\n",
    "\n",
    "### Objectives  \n",
    "- Perform **Exploratory Data Analysis (EDA)** to identify key trends.  \n",
    "- Analyze **sales performance, customer behavior, and popular products**.  \n",
    "- Provide **data-driven recommendations** to optimize online retail strategies.  \n",
    "\n",
    "\n",
    "### My Approach  \n",
    "To tackle this project, I’ll start by **ETL (Extract, Transform, Load)** to clean and prepare the dataset. Then, I’ll conduct in-depth analysis to identify key trends and insights like **busiest sales periods, top-selling products, and high-value customers**. Let's dive in!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this project, I'll be working with the **Online Retail** dataset, which contains transactional data from an online store between 2010 and 2011. The dataset is in a `.csv` file named **`online_retail.csv`**, and it includes details about purchases such as product descriptions, quantities, prices, timestamps, and customer IDs.  \n",
    "\n",
    "\n",
    "### Data Columns  \n",
    "The dataset consists of the following fields:  \n",
    "- **InvoiceNo** – Unique invoice number for each transaction.  \n",
    "- **StockCode** – Unique product identifier.  \n",
    "- **Description** – Product name/description.  \n",
    "- **Quantity** – Number of units purchased.  \n",
    "- **InvoiceDate** – Timestamp of the transaction.  \n",
    "- **UnitPrice** – Price per unit of the product.  \n",
    "- **CustomerID** – Unique identifier for each customer.  \n",
    "- **Country** – Country where the transaction took place.  \n",
    "\n",
    "\n",
    "### My Approach  \n",
    "\n",
    "To analyze this dataset effectively, I’ll break the process into key steps:  \n",
    "\n",
    "1. **Load the data** into a Pandas DataFrame and inspect the first few rows.  \n",
    "2. **Clean the dataset** by handling missing values and removing unnecessary data.  \n",
    "3. **Explore basic statistics** to understand distributions and trends.  \n",
    "4. **Visualize the data** using plots such as histograms, bar charts, and scatter plots.  \n",
    "5. **Analyze sales trends** over time to identify peak sales periods.  \n",
    "6. **Identify top-selling products and countries** based on quantity sold.  \n",
    "7. **Detect anomalies or outliers** that may impact the analysis.  \n",
    "8. **Summarize key findings** and insights from the data.  \n",
    "\n",
    "Let's dive in and explore the dataset!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"source/online_retail.csv\", encoding=\"ISO-8859-1\")  # We use encoding to avoid UnicodeDecodeError (or encoding=\"Windows-1252\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore and familiarize with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>541909.000000</td>\n",
       "      <td>541909.000000</td>\n",
       "      <td>406829.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.552250</td>\n",
       "      <td>4.611114</td>\n",
       "      <td>15287.690570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>218.081158</td>\n",
       "      <td>96.759853</td>\n",
       "      <td>1713.600303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-80995.000000</td>\n",
       "      <td>-11062.060000</td>\n",
       "      <td>12346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>13953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>15152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>16791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80995.000000</td>\n",
       "      <td>38970.000000</td>\n",
       "      <td>18287.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Quantity      UnitPrice     CustomerID\n",
       "count  541909.000000  541909.000000  406829.000000\n",
       "mean        9.552250       4.611114   15287.690570\n",
       "std       218.081158      96.759853    1713.600303\n",
       "min    -80995.000000  -11062.060000   12346.000000\n",
       "25%         1.000000       1.250000   13953.000000\n",
       "50%         3.000000       2.080000   15152.000000\n",
       "75%        10.000000       4.130000   16791.000000\n",
       "max     80995.000000   38970.000000   18287.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Clean the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the data types of each column and detected any missing (null) values, we have a clearer understanding of how to approach the ETL process.\n",
    "\n",
    "Before proceeding, let's create a copy of the dataframe to preserve the original data in its unaltered state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the copy created, we will begin by modifying the data types of specific columns.  \n",
    "In this case, we will convert the `Country`, `InvoiceNo`, and `StockCode` columns from the object type to the category type.  \n",
    "This transformation will optimize memory usage and improve performance when handling these columns in Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Country'] = df_clean['Country'].astype('category')\n",
    "df_clean['InvoiceNo'] = df_clean['InvoiceNo'].astype('category')\n",
    "df_clean['StockCode'] = df_clean['StockCode'].astype('category')\n",
    "\n",
    "# Ensure the data types where set correctly with: df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can also make sure that CustomerID is `int` instead of `float` to help Pandas process the information more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['CustomerID'] = df_clean['CustomerID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing `CustomerID` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains missing values in the `CustomerID` column, but these transactions are still valid purchases. Instead of dropping them or imputing arbitrary values (which could introduce bias), I will leave them as `NaN`.\n",
    "\n",
    " Why?\n",
    "- Removing these rows would result in **loss of actual transaction data**.\n",
    "- Imputing fake IDs would be **misleading**, as customer IDs are unique identifiers.\n",
    "- Pandas and Matplotlib **handle NaN values gracefully** in most operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing `Description` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains null values in the `Description` column. Since these rows cannot be dropped without losing valuable data, we impute the missing descriptions using the corresponding `StockCode` values (which are complete and unique).\n",
    "\n",
    "For that purpose, we follow this steps:\n",
    "1. **Create a mapping dictionary** where each `StockCode` points to its correct `Description` (using only rows with non-null descriptions)\n",
    "2. **Fill null values** by matching each missing `Description` with its `StockCode`'s known description\n",
    "\n",
    "**Key Note**: If a `StockCode` has no valid description in the dataset, its `NaN` values will remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Map StockCode to Description (drop duplicates to ensure 1:1 mapping)\n",
    "stock_to_desc = df_clean.dropna(subset=['Description']).drop_duplicates('StockCode').set_index('StockCode')['Description']\n",
    "\n",
    "# Step 2: Fill NaN Descriptions using the mapped StockCode values\n",
    "df_clean['Description'] = df_clean['Description'].fillna(df_clean['StockCode'].map(stock_to_desc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After handling the preliminary missing values in the `Description` column, it's important to verify if any null values still remain. We will perform this check to ensure that all missing descriptions have been properly handled before moving forward with further analysis.\n",
    "\n",
    "To do so, we'll check for any remaining nulls in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Description column null values: 1454\n",
      "Updated Description column null values: 112\n"
     ]
    }
   ],
   "source": [
    "# This will give us an updated count of the missing values in the 'Description' column\n",
    "print(f'Original Description column null values: {df['Description'].isna().sum()}')\n",
    "print(f'Updated Description column null values: {df_clean['Description'].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputing Remaining Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking for null values, we found that 112 missing descriptions remain out of the initial 1,454 null values. To ensure we don't lose valuable transaction data, we will impute these remaining null values with the placeholder `'Unknown'`. This decision allows us to retain all rows in the dataset while clearly marking the transactions with missing descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Description'] = df_clean['Description'].fillna('Unknown')\n",
    "\n",
    "# To make sure this worked as intended: print(df_clean['Description'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this, we preserve the full dataset while handling missing descriptions in a way that keeps the integrity of our analysis intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before removing duplicates, we need to ensure that all truly identical rows are recognized as such by Pandas. To achieve this, we will standardize string formatting to eliminate inconsistencies.\n",
    "\n",
    "We will focus on two key columns: `Description` and `Country`, as they contain string-type data.\n",
    "\n",
    "`Description`: We will remove leading, trailing, and extra in-between whitespaces and standardize all text to uppercase for consistency.\n",
    "\n",
    "`Country`: Similarly, we will trim unnecessary spaces and format country names in title case (first letter uppercase, the rest lowercase).\n",
    "\n",
    "These transformations will help ensure that duplicate records are correctly identified and handled in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Description: Remove leading/trailing spaces, handle in-between extra spaces, and standardize to lowercase\n",
    "df_clean['Description'] = df_clean['Description'].str.strip().str.replace(r'\\s+', ' ', regex=True).str.upper()\n",
    "\n",
    "# Clean Country: Remove leading/trailing spaces, handle in-between extra spaces, and title-case the country names\n",
    "df_clean['Country'] = df_clean['Country'].str.strip().str.replace(r'\\s+', ' ', regex=True).str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicated values can introduce bias and lead to incorrect insights, making it essential to handle them properly.\n",
    "\n",
    "To begin, we will check for duplicate records in the dataset. Since individual columns may contain duplicate values, our focus will be on identifying and removing rows where all columns are identical.\n",
    "\n",
    "For this, we will use Pandas' `.drop_duplicates()` method, which efficiently eliminates fully duplicated rows, ensuring data integrity for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 5268\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of duplicate rows: {df_clean.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicate rows\n",
    "df_clean = df_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating Negative Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of `df.describe()` in the *Load the Data* step, we identified negative values in the `Quantity` and `UnitPrice` columns. Since these values are not expected in a standard sales dataset, we will handle them systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10587\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Check for negative values in Quantity and UnitPrice\n",
    "print(df_clean[df_clean['Quantity'] < 0].shape[0])\n",
    "print(df_clean[df_clean['UnitPrice'] < 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of negative values in the `Quantity` column is significantly higher, we will address them first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizing the negative values in `Quantity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173241</th>\n",
       "      <td>551663</td>\n",
       "      <td>84548</td>\n",
       "      <td>CROCHET BEAR RED/BLUE KEYRING</td>\n",
       "      <td>-70</td>\n",
       "      <td>5/3/2011 12:34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394088</th>\n",
       "      <td>C570867</td>\n",
       "      <td>23349</td>\n",
       "      <td>ROLL WRAP VINTAGE CHRISTMAS</td>\n",
       "      <td>-12</td>\n",
       "      <td>10/12/2011 16:17</td>\n",
       "      <td>1.25</td>\n",
       "      <td>12607</td>\n",
       "      <td>Usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250161</th>\n",
       "      <td>C559007</td>\n",
       "      <td>23110</td>\n",
       "      <td>PARISIENNE KEY CABINET</td>\n",
       "      <td>-2</td>\n",
       "      <td>7/5/2011 12:42</td>\n",
       "      <td>5.75</td>\n",
       "      <td>13534</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221645</th>\n",
       "      <td>556262</td>\n",
       "      <td>37327</td>\n",
       "      <td>SOLD AS SET ON DOTCOM</td>\n",
       "      <td>-95</td>\n",
       "      <td>6/9/2011 18:04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431996</th>\n",
       "      <td>C573779</td>\n",
       "      <td>22928</td>\n",
       "      <td>YELLOW GIANT GARDEN THERMOMETER</td>\n",
       "      <td>-1</td>\n",
       "      <td>11/1/2011 10:57</td>\n",
       "      <td>5.95</td>\n",
       "      <td>16360</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291607</th>\n",
       "      <td>562464</td>\n",
       "      <td>20701</td>\n",
       "      <td>PINK CAT FLORAL CUSHION COVER</td>\n",
       "      <td>-24</td>\n",
       "      <td>8/5/2011 11:31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143310</th>\n",
       "      <td>548684</td>\n",
       "      <td>72798C</td>\n",
       "      <td>SET/4 GARDEN ROSE DINNER CANDLE</td>\n",
       "      <td>-2</td>\n",
       "      <td>4/1/2011 16:46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294923</th>\n",
       "      <td>C562728</td>\n",
       "      <td>22849</td>\n",
       "      <td>BREAD BIN DINER STYLE MINT</td>\n",
       "      <td>-1</td>\n",
       "      <td>8/9/2011 9:41</td>\n",
       "      <td>14.95</td>\n",
       "      <td>12406</td>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538063</th>\n",
       "      <td>C581384</td>\n",
       "      <td>51008</td>\n",
       "      <td>AFGHAN SLIPPER SOCK PAIR</td>\n",
       "      <td>-2</td>\n",
       "      <td>12/8/2011 13:06</td>\n",
       "      <td>3.45</td>\n",
       "      <td>17673</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454402</th>\n",
       "      <td>C575573</td>\n",
       "      <td>21535</td>\n",
       "      <td>RED RETROSPOT SMALL MILK JUG</td>\n",
       "      <td>-1</td>\n",
       "      <td>11/10/2011 11:34</td>\n",
       "      <td>2.55</td>\n",
       "      <td>16705</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273698</th>\n",
       "      <td>C560855</td>\n",
       "      <td>22666</td>\n",
       "      <td>RECIPE BOX PANTRY YELLOW DESIGN</td>\n",
       "      <td>-1</td>\n",
       "      <td>7/21/2011 13:00</td>\n",
       "      <td>2.95</td>\n",
       "      <td>14410</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224419</th>\n",
       "      <td>C556522</td>\n",
       "      <td>22920</td>\n",
       "      <td>HERB MARKER BASIL</td>\n",
       "      <td>-1515</td>\n",
       "      <td>6/13/2011 11:21</td>\n",
       "      <td>0.55</td>\n",
       "      <td>16938</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497459</th>\n",
       "      <td>C578371</td>\n",
       "      <td>84987</td>\n",
       "      <td>SET OF 36 TEATIME PAPER DOILIES</td>\n",
       "      <td>-1</td>\n",
       "      <td>11/24/2011 11:16</td>\n",
       "      <td>1.45</td>\n",
       "      <td>14410</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187022</th>\n",
       "      <td>C552919</td>\n",
       "      <td>21558</td>\n",
       "      <td>SKULL LUNCH BOX WITH CUTLERY</td>\n",
       "      <td>-1</td>\n",
       "      <td>5/12/2011 11:23</td>\n",
       "      <td>2.55</td>\n",
       "      <td>13282</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297523</th>\n",
       "      <td>C562952</td>\n",
       "      <td>23235</td>\n",
       "      <td>STORAGE TIN VINTAGE LEAF</td>\n",
       "      <td>-2</td>\n",
       "      <td>8/11/2011 10:10</td>\n",
       "      <td>2.89</td>\n",
       "      <td>12749</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203628</th>\n",
       "      <td>C554529</td>\n",
       "      <td>23174</td>\n",
       "      <td>REGENCY SUGAR BOWL GREEN</td>\n",
       "      <td>-1</td>\n",
       "      <td>5/24/2011 17:27</td>\n",
       "      <td>4.15</td>\n",
       "      <td>14226</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385940</th>\n",
       "      <td>C570221</td>\n",
       "      <td>22355</td>\n",
       "      <td>CHARLOTTE BAG SUKI DESIGN</td>\n",
       "      <td>-9</td>\n",
       "      <td>10/9/2011 12:56</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13113</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21517</th>\n",
       "      <td>C538089</td>\n",
       "      <td>21906</td>\n",
       "      <td>PHARMACIE FIRST AID TIN</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/9/2010 14:47</td>\n",
       "      <td>6.75</td>\n",
       "      <td>18230</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309590</th>\n",
       "      <td>C564108</td>\n",
       "      <td>21216</td>\n",
       "      <td>SET 3 RETROSPOT TEA,COFFEE,SUGAR</td>\n",
       "      <td>-1</td>\n",
       "      <td>8/23/2011 10:42</td>\n",
       "      <td>4.95</td>\n",
       "      <td>12428</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147789</th>\n",
       "      <td>549134</td>\n",
       "      <td>20758</td>\n",
       "      <td>ABSTRACT CIRCLES POCKET BOOK</td>\n",
       "      <td>-54</td>\n",
       "      <td>4/6/2011 15:22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                       Description  Quantity  \\\n",
       "173241    551663     84548     CROCHET BEAR RED/BLUE KEYRING       -70   \n",
       "394088   C570867     23349       ROLL WRAP VINTAGE CHRISTMAS       -12   \n",
       "250161   C559007     23110            PARISIENNE KEY CABINET        -2   \n",
       "221645    556262     37327             SOLD AS SET ON DOTCOM       -95   \n",
       "431996   C573779     22928   YELLOW GIANT GARDEN THERMOMETER        -1   \n",
       "291607    562464     20701     PINK CAT FLORAL CUSHION COVER       -24   \n",
       "143310    548684    72798C   SET/4 GARDEN ROSE DINNER CANDLE        -2   \n",
       "294923   C562728     22849        BREAD BIN DINER STYLE MINT        -1   \n",
       "538063   C581384     51008          AFGHAN SLIPPER SOCK PAIR        -2   \n",
       "454402   C575573     21535      RED RETROSPOT SMALL MILK JUG        -1   \n",
       "273698   C560855     22666   RECIPE BOX PANTRY YELLOW DESIGN        -1   \n",
       "224419   C556522     22920                 HERB MARKER BASIL     -1515   \n",
       "497459   C578371     84987   SET OF 36 TEATIME PAPER DOILIES        -1   \n",
       "187022   C552919     21558      SKULL LUNCH BOX WITH CUTLERY        -1   \n",
       "297523   C562952     23235          STORAGE TIN VINTAGE LEAF        -2   \n",
       "203628   C554529     23174          REGENCY SUGAR BOWL GREEN        -1   \n",
       "385940   C570221     22355         CHARLOTTE BAG SUKI DESIGN        -9   \n",
       "21517    C538089     21906           PHARMACIE FIRST AID TIN        -1   \n",
       "309590   C564108     21216  SET 3 RETROSPOT TEA,COFFEE,SUGAR        -1   \n",
       "147789    549134     20758      ABSTRACT CIRCLES POCKET BOOK       -54   \n",
       "\n",
       "             InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "173241    5/3/2011 12:34       0.00        <NA>  United Kingdom  \n",
       "394088  10/12/2011 16:17       1.25       12607             Usa  \n",
       "250161    7/5/2011 12:42       5.75       13534  United Kingdom  \n",
       "221645    6/9/2011 18:04       0.00        <NA>  United Kingdom  \n",
       "431996   11/1/2011 10:57       5.95       16360  United Kingdom  \n",
       "291607    8/5/2011 11:31       0.00        <NA>  United Kingdom  \n",
       "143310    4/1/2011 16:46       0.00        <NA>  United Kingdom  \n",
       "294923     8/9/2011 9:41      14.95       12406         Denmark  \n",
       "538063   12/8/2011 13:06       3.45       17673  United Kingdom  \n",
       "454402  11/10/2011 11:34       2.55       16705  United Kingdom  \n",
       "273698   7/21/2011 13:00       2.95       14410  United Kingdom  \n",
       "224419   6/13/2011 11:21       0.55       16938  United Kingdom  \n",
       "497459  11/24/2011 11:16       1.45       14410  United Kingdom  \n",
       "187022   5/12/2011 11:23       2.55       13282  United Kingdom  \n",
       "297523   8/11/2011 10:10       2.89       12749  United Kingdom  \n",
       "203628   5/24/2011 17:27       4.15       14226  United Kingdom  \n",
       "385940   10/9/2011 12:56       0.85       13113  United Kingdom  \n",
       "21517    12/9/2010 14:47       6.75       18230  United Kingdom  \n",
       "309590   8/23/2011 10:42       4.95       12428         Finland  \n",
       "147789    4/6/2011 15:22       0.00        <NA>  United Kingdom  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the negative values in Quantity and look for patterns\n",
    "df_clean[df_clean['Quantity'] < 0].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon examining the data, we can observe some patterns:  \n",
    "\n",
    "1. Most `InvoiceNo` values associated with negative quantities begin with \"C,\" which likely indicates a **credit transaction** (returns).  \n",
    "2. Some `Description` values suggest special cases, such as \"DAMAGED,\" \"DISCOUNT,\" or \"?\".  \n",
    "\n",
    "To better understand these cases, we will analyze how many unique `Description` values are associated with negative quantities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2471\n"
     ]
    }
   ],
   "source": [
    "negative_descriptions = df_clean[df_clean['Quantity'] < 0]['Description'].value_counts()\n",
    "print(negative_descriptions.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the large number of unique descriptions associated with negative quantities, we will focus on the most frequently occurring ones. This will help us identify common patterns and determine which descriptions may represent special cases that require specific handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description\n",
      "MANUAL                                 244\n",
      "REGENCY CAKESTAND 3 TIER               180\n",
      "POSTAGE                                126\n",
      "CHECK                                  123\n",
      "UNKNOWN                                 97\n",
      "JAM MAKING SET WITH JARS                87\n",
      "DISCOUNT                                77\n",
      "SET OF 3 CAKE TINS PANTRY DESIGN        75\n",
      "SAMPLES                                 61\n",
      "DAMAGED                                 57\n",
      "STRAWBERRY CERAMIC TRINKET BOX          54\n",
      "ROSES REGENCY TEACUP AND SAUCER         54\n",
      "RECIPE BOX PANTRY YELLOW DESIGN         47\n",
      "DAMAGES                                 46\n",
      "JUMBO BAG RED RETROSPOT                 44\n",
      "LUNCH BAG RED RETROSPOT                 44\n",
      "WOOD 2 DRAWER CABINET WHITE FINISH      43\n",
      "RED RETROSPOT CAKE STAND                42\n",
      "WHITE HANGING HEART T-LIGHT HOLDER      42\n",
      "GREEN REGENCY TEACUP AND SAUCER         42\n",
      "?                                       42\n",
      "SMALL GLASS HEART TRINKET POT           40\n",
      "SET OF 3 REGENCY CAKE TINS              37\n",
      "POPCORN HOLDER                          36\n",
      "PINK REGENCY TEACUP AND SAUCER          36\n",
      "SET OF TEA COFFEE SUGAR TINS PANTRY     35\n",
      "SILVER HANGING T-LIGHT HOLDER           35\n",
      "CLASSIC GLASS COOKIE JAR                34\n",
      "SET/5 RED RETROSPOT LID GLASS BOWLS     34\n",
      "AMAZON FEE                              32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(negative_descriptions.head(30))  # Show the top 30 most frequent negative descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the negative values in `Quantity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that some `Description` values represent regular products, while others indicate special cases (discounts, damaged products, or ambiguous values like \"?\"). We implement a unified classification system:\n",
    "\n",
    "1. Categorize All Transactions\n",
    "\n",
    "    Create a `TransactionType` column with three distinct labels:\n",
    "\n",
    "    * **Return:** Transactions where `InvoiceNo` starts with \"C\" (credit notes).\n",
    "    * **SpecialCase:** Transactions with descriptions matching predefined non-product terms (DISCOUNT, DAMAGED, SAMPLES, ?, etc.).\n",
    "    * **Sale:** All other regular transactions.\n",
    "\n",
    "2. Process Negative Quantities\n",
    "\n",
    "    * **Returns:** Keep negatives (valid refund records).\n",
    "    * **Special Cases:** Preserve original values (context-dependent).\n",
    "    * **Sales:** Convert negatives to positives (assumed data entry errors).\n",
    "\n",
    "**Note:** To distinguish legitimate negative quantities from data entry errors:\n",
    "\n",
    "* Identified the top 30 most frequent descriptions for negative quantities\n",
    "\n",
    "* Manually selected non-product terms (e.g., `DISCOUNT`, `DAMAGED`, `?`)\n",
    "\n",
    "Resulting in the curated `special_case_list` used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined list of special cases for descriptions\n",
    "special_case_list = [\n",
    "    'DISCOUNT', 'DAMAGED', 'DAMAGES', 'SAMPLES', 'CHECK', 'MANUAL', 'POSTAGE', \n",
    "    'UNKNOWN', '?', 'AMAZON FEE', 'DOTCOM POSTAGE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_transaction(invoice_no, description):\n",
    "    \"\"\"Classify transaction as 'Return', 'SpecialCase', or 'Sale'.\"\"\"\n",
    "    if str(invoice_no).startswith('C'):\n",
    "        return 'Return'\n",
    "    elif description in special_case_list:\n",
    "        return 'SpecialCase'\n",
    "    else:\n",
    "        return 'Sale'\n",
    "\n",
    "# Use .map() efficiently by applying it on a tuple of (InvoiceNo, Description)\n",
    "df_clean['TransactionType'] = list(map(classify_transaction, df_clean['InvoiceNo'], df_clean['Description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert negatives to positives ONLY for regular Sales\n",
    "df_clean.loc[\n",
    "    (df_clean['TransactionType'] == 'Sale') & \n",
    "    (df_clean['Quantity'] < 0), \n",
    "    'Quantity'\n",
    "] = df_clean['Quantity'].abs()  # Or: *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify this approach worked as intended, we check if there are any negative `Quantity` values remaining that are neither classified as \"Return\" nor \"SpecialCase\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Return or SpecialCase negative `Quantity` values: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Non Return or SpecialCase negative `Quantity` values: {df_clean[\n",
    "    (df_clean['Quantity'] < 0) & \n",
    "    (~df_clean['TransactionType'].isin(['Return', 'SpecialCase']))\n",
    "].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the result is 0, it confirms that all negative `Quantity` values have been correctly handled according to our classification. We can now proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizing and handling the negative values in `UnitPrice`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed earlier, only two transactions have negative `UnitPrice` values. Given their small number, we can inspect them directly as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299983</th>\n",
       "      <td>A563186</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>8/12/2011 14:51</td>\n",
       "      <td>-11062.06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299984</th>\n",
       "      <td>A563187</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>8/12/2011 14:52</td>\n",
       "      <td>-11062.06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode      Description  Quantity      InvoiceDate  \\\n",
       "299983   A563186         B  ADJUST BAD DEBT         1  8/12/2011 14:51   \n",
       "299984   A563187         B  ADJUST BAD DEBT         1  8/12/2011 14:52   \n",
       "\n",
       "        UnitPrice  CustomerID         Country TransactionType  \n",
       "299983  -11062.06        <NA>  United Kingdom            Sale  \n",
       "299984  -11062.06        <NA>  United Kingdom            Sale  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['UnitPrice'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since they are labeled as \"ADJUST BAD DEBT,\" these transactions appear to represent financial adjustments rather than product sales.\n",
    "\n",
    "As these records are valid, we will keep them in the dataset and classify them under \"SpecialCase\" in the `TransactionType` column while preserving their negative values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure \"ADJUST BAD DEBT\" transactions are marked as SpecialCase\n",
    "df_clean.loc[df_clean['Description'] == 'ADJUST BAD DEBT', 'TransactionType'] = 'SpecialCase'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from our initial exploration of `UnitPrice` shows that some transactions contain exceptionally high values. Upon further inspection, we found that several of these do not represent actual product sales but rather special cases, such as fees, postage, or adjustments.\n",
    "\n",
    "1. Identifying High `UnitPrice` Transactions\n",
    "To detect potential outliers, we examined the top transactions sorted by `UnitPrice`:\n",
    "\n",
    "- Initially, we used `df_clean.nlargest(10, 'UnitPrice')` to inspect the highest values.\n",
    "\n",
    "- Many high `UnitPrice` values corresponded to non-product transactions, which are **not currently classified as SpecialCases** (e.g., \"DOTCOM POSTAGE\", \"THROW AWAY\", \"MOULDY, THROWN AWAY.\").\n",
    "\n",
    "- To refine our analysis, we iteratively excluded known non-product descriptions and re-ran the analysis to identify remaining cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222681</th>\n",
       "      <td>C556445</td>\n",
       "      <td>M</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>6/10/2011 15:31</td>\n",
       "      <td>38970.00</td>\n",
       "      <td>15098</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524602</th>\n",
       "      <td>C580605</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/5/2011 11:36</td>\n",
       "      <td>17836.46</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43702</th>\n",
       "      <td>C540117</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/5/2011 9:55</td>\n",
       "      <td>16888.02</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43703</th>\n",
       "      <td>C540118</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/5/2011 9:57</td>\n",
       "      <td>16453.71</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>C537630</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:04</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15017</th>\n",
       "      <td>537632</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>1</td>\n",
       "      <td>12/7/2010 15:08</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16356</th>\n",
       "      <td>C537651</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:49</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16232</th>\n",
       "      <td>C537644</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:34</td>\n",
       "      <td>13474.79</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524601</th>\n",
       "      <td>C580604</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/5/2011 11:35</td>\n",
       "      <td>11586.50</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299982</th>\n",
       "      <td>A563185</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>8/12/2011 14:50</td>\n",
       "      <td>11062.06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo  StockCode      Description  Quantity      InvoiceDate  \\\n",
       "222681   C556445          M           MANUAL        -1  6/10/2011 15:31   \n",
       "524602   C580605  AMAZONFEE       AMAZON FEE        -1  12/5/2011 11:36   \n",
       "43702    C540117  AMAZONFEE       AMAZON FEE        -1    1/5/2011 9:55   \n",
       "43703    C540118  AMAZONFEE       AMAZON FEE        -1    1/5/2011 9:57   \n",
       "15016    C537630  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:04   \n",
       "15017     537632  AMAZONFEE       AMAZON FEE         1  12/7/2010 15:08   \n",
       "16356    C537651  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:49   \n",
       "16232    C537644  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:34   \n",
       "524601   C580604  AMAZONFEE       AMAZON FEE        -1  12/5/2011 11:35   \n",
       "299982   A563185          B  ADJUST BAD DEBT         1  8/12/2011 14:50   \n",
       "\n",
       "        UnitPrice  CustomerID         Country TransactionType  \n",
       "222681   38970.00       15098  United Kingdom          Return  \n",
       "524602   17836.46        <NA>  United Kingdom          Return  \n",
       "43702    16888.02        <NA>  United Kingdom          Return  \n",
       "43703    16453.71        <NA>  United Kingdom          Return  \n",
       "15016    13541.33        <NA>  United Kingdom          Return  \n",
       "15017    13541.33        <NA>  United Kingdom     SpecialCase  \n",
       "16356    13541.33        <NA>  United Kingdom          Return  \n",
       "16232    13474.79        <NA>  United Kingdom          Return  \n",
       "524601   11586.50        <NA>  United Kingdom          Return  \n",
       "299982   11062.06        <NA>  United Kingdom     SpecialCase  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.nlargest(10, 'UnitPrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Filtering Out Non-Product Cases\n",
    "We applied a filtering step to exclude descriptions that represent fees, adjustments, or other special cases, ensuring that we focus on actual product-related outliers. The filtered descriptions include:\n",
    "\n",
    "    \"AMAZON FEE\", \"MANUAL\", \"DOTCOM POSTAGE\", \"BANK CHARGES\", \"ADJUST BAD DEBT\", \"POSTAGE\", \"DISCOUNT\", \"CRUK COMMISSION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222680</th>\n",
       "      <td>556444</td>\n",
       "      <td>22502</td>\n",
       "      <td>PICNIC BASKET WICKER 60 PIECES</td>\n",
       "      <td>60</td>\n",
       "      <td>6/10/2011 15:28</td>\n",
       "      <td>649.5</td>\n",
       "      <td>15098</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222682</th>\n",
       "      <td>556446</td>\n",
       "      <td>22502</td>\n",
       "      <td>PICNIC BASKET WICKER 60 PIECES</td>\n",
       "      <td>1</td>\n",
       "      <td>6/10/2011 15:33</td>\n",
       "      <td>649.5</td>\n",
       "      <td>15098</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242589</th>\n",
       "      <td>C558359</td>\n",
       "      <td>S</td>\n",
       "      <td>SAMPLES</td>\n",
       "      <td>-1</td>\n",
       "      <td>6/28/2011 15:10</td>\n",
       "      <td>570.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>536835</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>12/2/2010 18:06</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13145</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32484</th>\n",
       "      <td>539080</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>12/16/2010 8:41</td>\n",
       "      <td>295.0</td>\n",
       "      <td>16607</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36165</th>\n",
       "      <td>C539438</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/17/2010 15:11</td>\n",
       "      <td>295.0</td>\n",
       "      <td>16607</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51636</th>\n",
       "      <td>540647</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>1/10/2011 14:57</td>\n",
       "      <td>295.0</td>\n",
       "      <td>17406</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82768</th>\n",
       "      <td>543253</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>2/4/2011 15:32</td>\n",
       "      <td>295.0</td>\n",
       "      <td>14842</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87141</th>\n",
       "      <td>C543632</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>-1</td>\n",
       "      <td>2/10/2011 16:22</td>\n",
       "      <td>295.0</td>\n",
       "      <td>14842</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118769</th>\n",
       "      <td>546480</td>\n",
       "      <td>22656</td>\n",
       "      <td>VINTAGE BLUE KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>3/14/2011 11:38</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13452</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                     Description  Quantity  \\\n",
       "222680    556444     22502  PICNIC BASKET WICKER 60 PIECES        60   \n",
       "222682    556446     22502  PICNIC BASKET WICKER 60 PIECES         1   \n",
       "242589   C558359         S                         SAMPLES        -1   \n",
       "4989      536835     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "32484     539080     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "36165    C539438     22655     VINTAGE RED KITCHEN CABINET        -1   \n",
       "51636     540647     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "82768     543253     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "87141    C543632     22655     VINTAGE RED KITCHEN CABINET        -1   \n",
       "118769    546480     22656    VINTAGE BLUE KITCHEN CABINET         1   \n",
       "\n",
       "             InvoiceDate  UnitPrice  CustomerID         Country  \\\n",
       "222680   6/10/2011 15:28      649.5       15098  United Kingdom   \n",
       "222682   6/10/2011 15:33      649.5       15098  United Kingdom   \n",
       "242589   6/28/2011 15:10      570.0        <NA>  United Kingdom   \n",
       "4989     12/2/2010 18:06      295.0       13145  United Kingdom   \n",
       "32484    12/16/2010 8:41      295.0       16607  United Kingdom   \n",
       "36165   12/17/2010 15:11      295.0       16607  United Kingdom   \n",
       "51636    1/10/2011 14:57      295.0       17406  United Kingdom   \n",
       "82768     2/4/2011 15:32      295.0       14842  United Kingdom   \n",
       "87141    2/10/2011 16:22      295.0       14842  United Kingdom   \n",
       "118769   3/14/2011 11:38      295.0       13452  United Kingdom   \n",
       "\n",
       "       TransactionType  \n",
       "222680            Sale  \n",
       "222682            Sale  \n",
       "242589          Return  \n",
       "4989              Sale  \n",
       "32484             Sale  \n",
       "36165           Return  \n",
       "51636             Sale  \n",
       "82768             Sale  \n",
       "87141           Return  \n",
       "118769            Sale  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[~df_clean['Description'].isin(\n",
    "    [\"AMAZON FEE\", \"MANUAL\", 'DOTCOM POSTAGE', 'BANK CHARGES', 'ADJUST BAD DEBT', 'POSTAGE', 'DISCOUNT', 'CRUK COMMISSION' \n",
    "    ])].nlargest(10, 'UnitPrice')\n",
    "\n",
    "# 'DOTCOM POSTAGE', 'THROW AWAY', 'UNSALEABLE, DESTROYED.', 'MOULDY, THROWN AWAY.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the identified outliers, we expand the `special_case_list` to include these descriptions and reuse the `classify_transaction` function, ensuring they are correctly categorized in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the special_case_list with newly identified non-product descriptions\n",
    "special_case_list.extend([\n",
    "    \"DOTCOM POSTAGE\", \"THROW AWAY\", \"UNSALEABLE, DESTROYED.\", \"MOULDY, THROWN AWAY.\",\n",
    "    \"AMAZON FEE\", \"MANUAL\", \"BANK CHARGES\", \"ADJUST BAD DEBT\", \"POSTAGE\", \"DISCOUNT\", \"CRUK COMMISSION\"\n",
    "])\n",
    "\n",
    "# Reapplying the classification function to update TransactionType\n",
    "df_clean['TransactionType'] = list(map(classify_transaction, df_clean['InvoiceNo'], df_clean['Description']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can re-run the high `UnitPrice`analysis to confirm that all outliers are either properly classified or remain legitimate product sales.\n",
    "\n",
    "By implementing this refined approach, we ensure that outlier removal is not arbitrary but instead data-driven, focusing on legitimate product transactions while flagging non-product entries as SpecialCases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222681</th>\n",
       "      <td>C556445</td>\n",
       "      <td>M</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>6/10/2011 15:31</td>\n",
       "      <td>38970.00</td>\n",
       "      <td>15098</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524602</th>\n",
       "      <td>C580605</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/5/2011 11:36</td>\n",
       "      <td>17836.46</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43702</th>\n",
       "      <td>C540117</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/5/2011 9:55</td>\n",
       "      <td>16888.02</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43703</th>\n",
       "      <td>C540118</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/5/2011 9:57</td>\n",
       "      <td>16453.71</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>C537630</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:04</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15017</th>\n",
       "      <td>537632</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>1</td>\n",
       "      <td>12/7/2010 15:08</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16356</th>\n",
       "      <td>C537651</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:49</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16232</th>\n",
       "      <td>C537644</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:34</td>\n",
       "      <td>13474.79</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524601</th>\n",
       "      <td>C580604</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/5/2011 11:35</td>\n",
       "      <td>11586.50</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299982</th>\n",
       "      <td>A563185</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>8/12/2011 14:50</td>\n",
       "      <td>11062.06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo  StockCode      Description  Quantity      InvoiceDate  \\\n",
       "222681   C556445          M           MANUAL        -1  6/10/2011 15:31   \n",
       "524602   C580605  AMAZONFEE       AMAZON FEE        -1  12/5/2011 11:36   \n",
       "43702    C540117  AMAZONFEE       AMAZON FEE        -1    1/5/2011 9:55   \n",
       "43703    C540118  AMAZONFEE       AMAZON FEE        -1    1/5/2011 9:57   \n",
       "15016    C537630  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:04   \n",
       "15017     537632  AMAZONFEE       AMAZON FEE         1  12/7/2010 15:08   \n",
       "16356    C537651  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:49   \n",
       "16232    C537644  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:34   \n",
       "524601   C580604  AMAZONFEE       AMAZON FEE        -1  12/5/2011 11:35   \n",
       "299982   A563185          B  ADJUST BAD DEBT         1  8/12/2011 14:50   \n",
       "\n",
       "        UnitPrice  CustomerID         Country TransactionType  \n",
       "222681   38970.00       15098  United Kingdom          Return  \n",
       "524602   17836.46        <NA>  United Kingdom          Return  \n",
       "43702    16888.02        <NA>  United Kingdom          Return  \n",
       "43703    16453.71        <NA>  United Kingdom          Return  \n",
       "15016    13541.33        <NA>  United Kingdom          Return  \n",
       "15017    13541.33        <NA>  United Kingdom     SpecialCase  \n",
       "16356    13541.33        <NA>  United Kingdom          Return  \n",
       "16232    13474.79        <NA>  United Kingdom          Return  \n",
       "524601   11586.50        <NA>  United Kingdom          Return  \n",
       "299982   11062.06        <NA>  United Kingdom     SpecialCase  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.nlargest(10, 'UnitPrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Explore basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the dataset, we proceed to explore its basic statistics. This initial analysis provides a foundation for understanding the data’s structure, identifying early patterns, and evaluating potential anomalies or irregularities. It sets the stage for more advanced analytical steps by offering a general snapshot of the dataset’s composition.\n",
    "\n",
    "We begin by generating summary statistics and exploring key aspects of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 536641 entries, 0 to 541908\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype   \n",
      "---  ------           --------------   -----   \n",
      " 0   InvoiceNo        536641 non-null  category\n",
      " 1   StockCode        536641 non-null  category\n",
      " 2   Description      536641 non-null  object  \n",
      " 3   Quantity         536641 non-null  int64   \n",
      " 4   InvoiceDate      536641 non-null  object  \n",
      " 5   UnitPrice        536641 non-null  float64 \n",
      " 6   CustomerID       401604 non-null  Int64   \n",
      " 7   Country          536641 non-null  object  \n",
      " 8   TransactionType  536641 non-null  object  \n",
      "dtypes: Int64(1), category(2), float64(1), int64(1), object(4)\n",
      "memory usage: 52.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Observations:**\n",
    "\n",
    "- **Rows**: 536,641 transactions\n",
    "- **Columns**: 9\n",
    "- Missing Values: Most columns are complete, except for CustomerID, which is missing in approximately 25% of the records\n",
    "- **Derived Column**: A new column, `TransactionType`, classifies each row as a `Sale`, `Return`, or `SpecialCase` based on invoice patterns and product descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionType\n",
       "Sale           0.977879\n",
       "Return         0.017239\n",
       "SpecialCase    0.004882\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['TransactionType'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of transactions are regular **Sales**, followed by a smaller proportion of **Returns** and **Special Cases**, as expected based on our previous classification process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of each transaction type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having all transactions categorized under `TransactionType`, we can now analyze each group independently without conflating their behaviors. This allows for more accurate insights and better handling of specific cases.\n",
    "\n",
    "To begin, we use the `.describe()` method to generate summary statistics for each transaction type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>524770.000000</td>\n",
       "      <td>524770.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.987383</td>\n",
       "      <td>3.274727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>159.878853</td>\n",
       "      <td>4.460465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80995.000000</td>\n",
       "      <td>649.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Quantity      UnitPrice\n",
       "count  524770.000000  524770.000000\n",
       "mean       10.987383       3.274727\n",
       "std       159.878853       4.460465\n",
       "min         1.000000       0.000000\n",
       "25%         1.000000       1.250000\n",
       "50%         4.000000       2.080000\n",
       "75%        12.000000       4.130000\n",
       "max     80995.000000     649.500000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['TransactionType'] == 'Sale'].drop(columns=['CustomerID']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9251.000000</td>\n",
       "      <td>9251.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-29.787050</td>\n",
       "      <td>48.570430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1147.997592</td>\n",
       "      <td>667.926393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-80995.000000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.000000</td>\n",
       "      <td>1.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>2.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>38970.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Quantity     UnitPrice\n",
       "count   9251.000000   9251.000000\n",
       "mean     -29.787050     48.570430\n",
       "std     1147.997592    667.926393\n",
       "min   -80995.000000      0.010000\n",
       "25%       -6.000000      1.450000\n",
       "50%       -2.000000      2.950000\n",
       "75%       -1.000000      5.950000\n",
       "max       -1.000000  38970.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['TransactionType'] == 'Return'].drop(columns=['CustomerID']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2620.000000</td>\n",
       "      <td>2620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.115649</td>\n",
       "      <td>121.476855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>232.965881</td>\n",
       "      <td>580.267542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3000.000000</td>\n",
       "      <td>-11062.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>118.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5368.000000</td>\n",
       "      <td>13541.330000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Quantity     UnitPrice\n",
       "count  2620.000000   2620.000000\n",
       "mean      4.115649    121.476855\n",
       "std     232.965881    580.267542\n",
       "min   -3000.000000 -11062.060000\n",
       "25%       1.000000      2.950000\n",
       "50%       1.000000     18.000000\n",
       "75%       2.000000    118.342500\n",
       "max    5368.000000  13541.330000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['TransactionType'] == 'SpecialCase'].drop(columns=['CustomerID']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "\n",
    "- **Returns** correctly reflect negative quantities, consistent with refund transactions.\n",
    "- **Special Cases** exhibit high variability in both `Quantity` and `UnitPrice`, supporting their exclusion from regular sales analysis.\n",
    "- **Sales** now contain only positive quantities and show a reasonable distribution of unit prices, indicating reliable data for core business analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Revenue metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a preliminary step toward deeper financial analysis, we introduce a new column called `Revenue`, calculated as the product of `Quantity` and `UnitPrice`.\n",
    "\n",
    "This allows us to quickly estimate the total revenue generated from valid sales transactions and establish a foundation for further performance metrics in the following sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Revenue'] = df_clean['Quantity'] * df_clean['UnitPrice']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
