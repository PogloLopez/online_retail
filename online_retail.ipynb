{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Project: Online Retail EDA with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project explores an **online retail transactions dataset**, focusing on **data cleaning, exploratory data analysis (EDA), and deriving business insights**. The dataset contains information about customer purchases, including invoice details, product descriptions, quantities, prices, and customer IDs. \n",
    "\n",
    "\n",
    "### Objectives  \n",
    "- Perform **Exploratory Data Analysis (EDA)** to identify key trends.  \n",
    "- Analyze **sales performance, customer behavior, and popular products**.  \n",
    "- Provide **data-driven recommendations** to optimize online retail strategies.  \n",
    "\n",
    "\n",
    "### My Approach  \n",
    "To tackle this project, I’ll start by **ETL (Extract, Transform, Load)** to clean and prepare the dataset. Then, I’ll conduct in-depth analysis to identify key trends and insights like **busiest sales periods, top-selling products, and high-value customers**. Let's dive in!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this project, I'll be working with the **Online Retail** dataset, which contains transactional data from an online store between 2010 and 2011. The dataset is in a `.csv` file named **`online_retail.csv`**, and it includes details about purchases such as product descriptions, quantities, prices, timestamps, and customer IDs.  \n",
    "\n",
    "\n",
    "### Data Columns  \n",
    "The dataset consists of the following fields:  \n",
    "- **InvoiceNo** – Unique invoice number for each transaction.  \n",
    "- **StockCode** – Unique product identifier.  \n",
    "- **Description** – Product name/description.  \n",
    "- **Quantity** – Number of units purchased.  \n",
    "- **InvoiceDate** – Timestamp of the transaction.  \n",
    "- **UnitPrice** – Price per unit of the product.  \n",
    "- **CustomerID** – Unique identifier for each customer.  \n",
    "- **Country** – Country where the transaction took place.  \n",
    "\n",
    "\n",
    "### My Approach  \n",
    "\n",
    "To analyze this dataset effectively, I’ll break the process into key steps:  \n",
    "\n",
    "1. **Load the data** into a Pandas DataFrame and inspect the first few rows.  \n",
    "2. **Clean the dataset** by handling missing values and removing unnecessary data.  \n",
    "3. **Explore basic statistics** to understand distributions and trends.  \n",
    "4. **Visualize the data** using plots such as histograms, bar charts, and scatter plots.  \n",
    "5. **Analyze sales trends** over time to identify peak sales periods.  \n",
    "6. **Identify top-selling products and countries** based on quantity sold.  \n",
    "7. **Detect anomalies or outliers** that may impact the analysis.  \n",
    "8. **Summarize key findings** and insights from the data.  \n",
    "\n",
    "Let's dive in and explore the dataset!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"source/online_retail.csv\", encoding=\"ISO-8859-1\")  # We use encoding to avoid UnicodeDecodeError (or encoding=\"Windows-1252\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore and familiarize with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>541909.000000</td>\n",
       "      <td>541909.000000</td>\n",
       "      <td>406829.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.552250</td>\n",
       "      <td>4.611114</td>\n",
       "      <td>15287.690570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>218.081158</td>\n",
       "      <td>96.759853</td>\n",
       "      <td>1713.600303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-80995.000000</td>\n",
       "      <td>-11062.060000</td>\n",
       "      <td>12346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>13953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>15152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>16791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80995.000000</td>\n",
       "      <td>38970.000000</td>\n",
       "      <td>18287.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Quantity      UnitPrice     CustomerID\n",
       "count  541909.000000  541909.000000  406829.000000\n",
       "mean        9.552250       4.611114   15287.690570\n",
       "std       218.081158      96.759853    1713.600303\n",
       "min    -80995.000000  -11062.060000   12346.000000\n",
       "25%         1.000000       1.250000   13953.000000\n",
       "50%         3.000000       2.080000   15152.000000\n",
       "75%        10.000000       4.130000   16791.000000\n",
       "max     80995.000000   38970.000000   18287.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Clean the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the data types of each column and detected any missing (null) values, we have a clearer understanding of how to approach the ETL process.\n",
    "\n",
    "Before proceeding, let's create a copy of the dataframe to preserve the original data in its unaltered state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the copy created, we will begin by modifying the data types of specific columns.  \n",
    "In this case, we will convert the `Country`, `InvoiceNo`, and `StockCode` columns from the object type to the category type.  \n",
    "This transformation will optimize memory usage and improve performance when handling these columns in Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Country'] = df['Country'].astype('category')\n",
    "df_clean['InvoiceNo'] = df['InvoiceNo'].astype('category')\n",
    "df_clean['StockCode'] = df['StockCode'].astype('category')\n",
    "\n",
    "# Ensure the data types where set correctly with: df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing `CustomerID` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains missing values in the `CustomerID` column, but these transactions are still valid purchases. Instead of dropping them or imputing arbitrary values (which could introduce bias), I will leave them as `NaN`.\n",
    "\n",
    " Why?\n",
    "- Removing these rows would result in **loss of actual transaction data**.\n",
    "- Imputing fake IDs would be **misleading**, as customer IDs are unique identifiers.\n",
    "- Pandas and Matplotlib **handle NaN values gracefully** in most operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing `Description` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains null values in the `Description` column. Since these rows cannot be dropped without losing valuable data, we impute the missing descriptions using the corresponding `StockCode` values (which are complete and unique).\n",
    "\n",
    "For that purpose, we follow this steps:\n",
    "1. **Create a mapping dictionary** where each `StockCode` points to its correct `Description` (using only rows with non-null descriptions)\n",
    "2. **Fill null values** by matching each missing `Description` with its `StockCode`'s known description\n",
    "\n",
    "**Key Note**: If a `StockCode` has no valid description in the dataset, its `NaN` values will remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Map StockCode to Description (drop duplicates to ensure 1:1 mapping)\n",
    "stock_to_desc = df_clean.dropna(subset=['Description']).drop_duplicates('StockCode').set_index('StockCode')['Description']\n",
    "\n",
    "# Step 2: Fill NaN Descriptions using the mapped StockCode values\n",
    "df_clean['Description'] = df_clean['Description'].fillna(df_clean['StockCode'].map(stock_to_desc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After handling the preliminary missing values in the `Description` column, it's important to verify if any null values still remain. We will perform this check to ensure that all missing descriptions have been properly handled before moving forward with further analysis.\n",
    "\n",
    "To do so, we'll check for any remaining nulls in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Description column null values: 1454\n",
      "Updated Description column null values: 112\n"
     ]
    }
   ],
   "source": [
    "# This will give us an updated count of the missing values in the 'Description' column\n",
    "print(f'Original Description column null values: {df['Description'].isna().sum()}')\n",
    "print(f'Updated Description column null values: {df_clean['Description'].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputing Remaining Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking for null values, we found that 112 missing descriptions remain out of the initial 1,454 null values. To ensure we don't lose valuable transaction data, we will impute these remaining null values with the placeholder `'Unknown'`. This decision allows us to retain all rows in the dataset while clearly marking the transactions with missing descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Description'] = df_clean['Description'].fillna('Unknown')\n",
    "\n",
    "# To make sure this worked as intended: print(df_clean['Description'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this, we preserve the full dataset while handling missing descriptions in a way that keeps the integrity of our analysis intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before removing duplicates, we need to ensure that all truly identical rows are recognized as such by Pandas. To achieve this, we will standardize string formatting to eliminate inconsistencies.\n",
    "\n",
    "We will focus on two key columns: `Description` and `Country`, as they contain string-type data.\n",
    "\n",
    "`Description`: We will remove leading, trailing, and extra in-between whitespaces and standardize all text to uppercase for consistency.\n",
    "\n",
    "`Country`: Similarly, we will trim unnecessary spaces and format country names in title case (first letter uppercase, the rest lowercase).\n",
    "\n",
    "These transformations will help ensure that duplicate records are correctly identified and handled in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Description: Remove leading/trailing spaces, handle in-between extra spaces, and standardize to lowercase\n",
    "df_clean['Description'] = df_clean['Description'].str.strip().str.replace(r'\\s+', ' ', regex=True).str.upper()\n",
    "\n",
    "# Clean Country: Remove leading/trailing spaces, handle in-between extra spaces, and title-case the country names\n",
    "df_clean['Country'] = df_clean['Country'].str.strip().str.replace(r'\\s+', ' ', regex=True).str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicated values can introduce bias and lead to incorrect insights, making it essential to handle them properly.\n",
    "\n",
    "To begin, we will check for duplicate records in the dataset. Since individual columns may contain duplicate values, our focus will be on identifying and removing rows where all columns are identical.\n",
    "\n",
    "For this, we will use Pandas' `.drop_duplicates()` method, which efficiently eliminates fully duplicated rows, ensuring data integrity for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 5268\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of duplicate rows: {df_clean.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicate rows\n",
    "df_clean = df_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating Negative Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of `df.describe()` in the *Load the Data* step, we identified negative values in the `Quantity` and `UnitPrice` columns. Since these values are not expected in a standard sales dataset, we will handle them systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10587\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Check for negative values in Quantity and UnitPrice\n",
    "print(df_clean[df_clean['Quantity'] < 0].shape[0])\n",
    "print(df_clean[df_clean['UnitPrice'] < 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of negative values in the `Quantity` column is significantly higher, we will address them first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizing the negative values in `Quantity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>C536825</td>\n",
       "      <td>22617</td>\n",
       "      <td>BAKING SET SPACEBOY DESIGN</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/2/2010 17:27</td>\n",
       "      <td>4.95</td>\n",
       "      <td>15384.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246779</th>\n",
       "      <td>C558727</td>\n",
       "      <td>22605</td>\n",
       "      <td>WOODEN CROQUET GARDEN SET</td>\n",
       "      <td>-1</td>\n",
       "      <td>7/1/2011 14:35</td>\n",
       "      <td>10.95</td>\n",
       "      <td>12709.0</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341273</th>\n",
       "      <td>C566741</td>\n",
       "      <td>23404</td>\n",
       "      <td>HOME SWEET HOME BLACKBOARD</td>\n",
       "      <td>-1</td>\n",
       "      <td>9/14/2011 14:55</td>\n",
       "      <td>4.95</td>\n",
       "      <td>15618.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96710</th>\n",
       "      <td>C544583</td>\n",
       "      <td>S</td>\n",
       "      <td>SAMPLES</td>\n",
       "      <td>-1</td>\n",
       "      <td>2/21/2011 14:48</td>\n",
       "      <td>37.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>C537251</td>\n",
       "      <td>22328</td>\n",
       "      <td>ROUND SNACK BOXES SET OF 4 FRUITS</td>\n",
       "      <td>-2</td>\n",
       "      <td>12/6/2010 10:45</td>\n",
       "      <td>2.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140748</th>\n",
       "      <td>C548460</td>\n",
       "      <td>48138</td>\n",
       "      <td>DOORMAT UNION FLAG</td>\n",
       "      <td>-2</td>\n",
       "      <td>3/31/2011 11:58</td>\n",
       "      <td>7.95</td>\n",
       "      <td>16801.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17134</th>\n",
       "      <td>C537684</td>\n",
       "      <td>22301</td>\n",
       "      <td>COFFEE MUG CAT + BIRD DESIGN</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/8/2010 10:18</td>\n",
       "      <td>2.55</td>\n",
       "      <td>14901.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271255</th>\n",
       "      <td>C560653</td>\n",
       "      <td>M</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>7/20/2011 11:40</td>\n",
       "      <td>451.42</td>\n",
       "      <td>15802.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107374</th>\n",
       "      <td>C545436</td>\n",
       "      <td>20725</td>\n",
       "      <td>LUNCH BAG RED RETROSPOT</td>\n",
       "      <td>-1</td>\n",
       "      <td>3/2/2011 15:52</td>\n",
       "      <td>1.65</td>\n",
       "      <td>13093.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516373</th>\n",
       "      <td>C579886</td>\n",
       "      <td>21172</td>\n",
       "      <td>PARTY METAL SIGN</td>\n",
       "      <td>-1</td>\n",
       "      <td>11/30/2011 17:39</td>\n",
       "      <td>1.45</td>\n",
       "      <td>15676.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160140</th>\n",
       "      <td>C550455</td>\n",
       "      <td>22382</td>\n",
       "      <td>LUNCH BAG SPACEBOY DESIGN</td>\n",
       "      <td>-1</td>\n",
       "      <td>4/18/2011 13:02</td>\n",
       "      <td>1.65</td>\n",
       "      <td>13098.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320761</th>\n",
       "      <td>C565089</td>\n",
       "      <td>22553</td>\n",
       "      <td>PLASTERS IN TIN SKULLS</td>\n",
       "      <td>-12</td>\n",
       "      <td>9/1/2011 10:27</td>\n",
       "      <td>1.65</td>\n",
       "      <td>12645.0</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75380</th>\n",
       "      <td>C542588</td>\n",
       "      <td>21730</td>\n",
       "      <td>GLASS STAR FROSTED T-LIGHT HOLDER</td>\n",
       "      <td>-2</td>\n",
       "      <td>1/28/2011 15:57</td>\n",
       "      <td>4.95</td>\n",
       "      <td>12997.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481165</th>\n",
       "      <td>C577346</td>\n",
       "      <td>M</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>11/18/2011 15:25</td>\n",
       "      <td>530.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328579</th>\n",
       "      <td>C565789</td>\n",
       "      <td>22488</td>\n",
       "      <td>NATURAL SLATE RECTANGLE CHALKBOARD</td>\n",
       "      <td>-12</td>\n",
       "      <td>9/7/2011 9:07</td>\n",
       "      <td>1.65</td>\n",
       "      <td>16735.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297540</th>\n",
       "      <td>C562952</td>\n",
       "      <td>23111</td>\n",
       "      <td>PARISIENNE SEWING BOX</td>\n",
       "      <td>-1</td>\n",
       "      <td>8/11/2011 10:10</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12749.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184926</th>\n",
       "      <td>C552720</td>\n",
       "      <td>22969</td>\n",
       "      <td>HOMEMADE JAM SCENTED CANDLES</td>\n",
       "      <td>-2</td>\n",
       "      <td>5/11/2011 9:49</td>\n",
       "      <td>1.45</td>\n",
       "      <td>18272.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356034</th>\n",
       "      <td>C567997</td>\n",
       "      <td>22776</td>\n",
       "      <td>SWEETHEART 3 TIER CAKE STAND</td>\n",
       "      <td>-1</td>\n",
       "      <td>9/23/2011 11:31</td>\n",
       "      <td>9.95</td>\n",
       "      <td>13097.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>C537234</td>\n",
       "      <td>22653</td>\n",
       "      <td>BUTTON BOX</td>\n",
       "      <td>-20</td>\n",
       "      <td>12/6/2010 9:40</td>\n",
       "      <td>1.95</td>\n",
       "      <td>16161.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329373</th>\n",
       "      <td>C565843</td>\n",
       "      <td>22151</td>\n",
       "      <td>PLACE SETTING WHITE HEART</td>\n",
       "      <td>-1</td>\n",
       "      <td>9/7/2011 12:15</td>\n",
       "      <td>0.42</td>\n",
       "      <td>14606.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                         Description  Quantity  \\\n",
       "4937     C536825     22617          BAKING SET SPACEBOY DESIGN        -1   \n",
       "246779   C558727     22605           WOODEN CROQUET GARDEN SET        -1   \n",
       "341273   C566741     23404          HOME SWEET HOME BLACKBOARD        -1   \n",
       "96710    C544583         S                             SAMPLES        -1   \n",
       "11518    C537251     22328   ROUND SNACK BOXES SET OF 4 FRUITS        -2   \n",
       "140748   C548460     48138                  DOORMAT UNION FLAG        -2   \n",
       "17134    C537684     22301        COFFEE MUG CAT + BIRD DESIGN        -1   \n",
       "271255   C560653         M                              MANUAL        -1   \n",
       "107374   C545436     20725             LUNCH BAG RED RETROSPOT        -1   \n",
       "516373   C579886     21172                    PARTY METAL SIGN        -1   \n",
       "160140   C550455     22382           LUNCH BAG SPACEBOY DESIGN        -1   \n",
       "320761   C565089     22553              PLASTERS IN TIN SKULLS       -12   \n",
       "75380    C542588     21730   GLASS STAR FROSTED T-LIGHT HOLDER        -2   \n",
       "481165   C577346         M                              MANUAL        -1   \n",
       "328579   C565789     22488  NATURAL SLATE RECTANGLE CHALKBOARD       -12   \n",
       "297540   C562952     23111               PARISIENNE SEWING BOX        -1   \n",
       "184926   C552720     22969        HOMEMADE JAM SCENTED CANDLES        -2   \n",
       "356034   C567997     22776        SWEETHEART 3 TIER CAKE STAND        -1   \n",
       "10204    C537234     22653                          BUTTON BOX       -20   \n",
       "329373   C565843     22151           PLACE SETTING WHITE HEART        -1   \n",
       "\n",
       "             InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "4937     12/2/2010 17:27       4.95     15384.0  United Kingdom  \n",
       "246779    7/1/2011 14:35      10.95     12709.0         Germany  \n",
       "341273   9/14/2011 14:55       4.95     15618.0  United Kingdom  \n",
       "96710    2/21/2011 14:48      37.49         NaN  United Kingdom  \n",
       "11518    12/6/2010 10:45       2.95         NaN  United Kingdom  \n",
       "140748   3/31/2011 11:58       7.95     16801.0  United Kingdom  \n",
       "17134    12/8/2010 10:18       2.55     14901.0  United Kingdom  \n",
       "271255   7/20/2011 11:40     451.42     15802.0  United Kingdom  \n",
       "107374    3/2/2011 15:52       1.65     13093.0  United Kingdom  \n",
       "516373  11/30/2011 17:39       1.45     15676.0  United Kingdom  \n",
       "160140   4/18/2011 13:02       1.65     13098.0  United Kingdom  \n",
       "320761    9/1/2011 10:27       1.65     12645.0         Germany  \n",
       "75380    1/28/2011 15:57       4.95     12997.0  United Kingdom  \n",
       "481165  11/18/2011 15:25     530.25         NaN  United Kingdom  \n",
       "328579     9/7/2011 9:07       1.65     16735.0  United Kingdom  \n",
       "297540   8/11/2011 10:10      12.50     12749.0  United Kingdom  \n",
       "184926    5/11/2011 9:49       1.45     18272.0  United Kingdom  \n",
       "356034   9/23/2011 11:31       9.95     13097.0  United Kingdom  \n",
       "10204     12/6/2010 9:40       1.95     16161.0  United Kingdom  \n",
       "329373    9/7/2011 12:15       0.42     14606.0  United Kingdom  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the negative values in Quantity and look for patterns\n",
    "df_clean[df_clean['Quantity'] < 0].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon examining the data, we can observe some patterns:  \n",
    "\n",
    "1. Most `InvoiceNo` values associated with negative quantities begin with \"C,\" which likely indicates a **credit transaction** (returns).  \n",
    "2. Some `Description` values suggest special cases, such as \"DAMAGED,\" \"DISCOUNT,\" or \"?\".  \n",
    "\n",
    "To better understand these cases, we will analyze how many unique `Description` values are associated with negative quantities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2471\n"
     ]
    }
   ],
   "source": [
    "negative_descriptions = df_clean[df_clean['Quantity'] < 0]['Description'].value_counts()\n",
    "print(negative_descriptions.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the large number of unique descriptions associated with negative quantities, we will focus on the most frequently occurring ones. This will help us identify common patterns and determine which descriptions may represent special cases that require specific handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description\n",
      "MANUAL                                 244\n",
      "REGENCY CAKESTAND 3 TIER               180\n",
      "POSTAGE                                126\n",
      "CHECK                                  123\n",
      "UNKNOWN                                 97\n",
      "JAM MAKING SET WITH JARS                87\n",
      "DISCOUNT                                77\n",
      "SET OF 3 CAKE TINS PANTRY DESIGN        75\n",
      "SAMPLES                                 61\n",
      "DAMAGED                                 57\n",
      "STRAWBERRY CERAMIC TRINKET BOX          54\n",
      "ROSES REGENCY TEACUP AND SAUCER         54\n",
      "RECIPE BOX PANTRY YELLOW DESIGN         47\n",
      "DAMAGES                                 46\n",
      "JUMBO BAG RED RETROSPOT                 44\n",
      "LUNCH BAG RED RETROSPOT                 44\n",
      "WOOD 2 DRAWER CABINET WHITE FINISH      43\n",
      "RED RETROSPOT CAKE STAND                42\n",
      "WHITE HANGING HEART T-LIGHT HOLDER      42\n",
      "GREEN REGENCY TEACUP AND SAUCER         42\n",
      "?                                       42\n",
      "SMALL GLASS HEART TRINKET POT           40\n",
      "SET OF 3 REGENCY CAKE TINS              37\n",
      "POPCORN HOLDER                          36\n",
      "PINK REGENCY TEACUP AND SAUCER          36\n",
      "SET OF TEA COFFEE SUGAR TINS PANTRY     35\n",
      "SILVER HANGING T-LIGHT HOLDER           35\n",
      "CLASSIC GLASS COOKIE JAR                34\n",
      "SET/5 RED RETROSPOT LID GLASS BOWLS     34\n",
      "AMAZON FEE                              32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(negative_descriptions.head(30))  # Show the top 30 most frequent negative descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the negative values in `Quantity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that some `Description` values represent regular products, while others indicate special cases (discounts, damaged products, or ambiguous values like \"?\"). We implement a unified classification system:\n",
    "\n",
    "1. Categorize All Transactions\n",
    "\n",
    "    Create a `TransactionType` column with three distinct labels:\n",
    "\n",
    "    * **Return:** Transactions where `InvoiceNo` starts with \"C\" (credit notes).\n",
    "    * **SpecialCase:** Transactions with descriptions matching predefined non-product terms (DISCOUNT, DAMAGED, SAMPLES, ?, etc.).\n",
    "    * **Sale:** All other regular transactions.\n",
    "\n",
    "2. Process Negative Quantities\n",
    "\n",
    "    * **Returns:** Keep negatives (valid refund records).\n",
    "    * **Special Cases:** Preserve original values (context-dependent).\n",
    "    * **Sales:** Convert negatives to positives (assumed data entry errors).\n",
    "\n",
    "**Note:** To distinguish legitimate negative quantities from data entry errors:\n",
    "\n",
    "* Identified the top 30 most frequent descriptions for negative quantities\n",
    "\n",
    "* Manually selected non-product terms (e.g., `DISCOUNT`, `DAMAGED`, `?`)\n",
    "\n",
    "Resulting in the curated `special_case_list` used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined list of special cases for descriptions\n",
    "special_case_list = [\n",
    "    'DISCOUNT', 'DAMAGED', 'DAMAGES', 'SAMPLES', 'CHECK', 'MANUAL', 'POSTAGE', \n",
    "    'UNKNOWN', '?', 'AMAZON FEE', 'DOTCOM POSTAGE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_transaction(invoice_no, description):\n",
    "    \"\"\"Classify transaction as 'Return', 'SpecialCase', or 'Sale'.\"\"\"\n",
    "    if str(invoice_no).startswith('C'):\n",
    "        return 'Return'\n",
    "    elif description in special_case_list:\n",
    "        return 'SpecialCase'\n",
    "    else:\n",
    "        return 'Sale'\n",
    "\n",
    "# Use .map() efficiently by applying it on a tuple of (InvoiceNo, Description)\n",
    "df_clean['TransactionType'] = list(map(classify_transaction, df_clean['InvoiceNo'], df_clean['Description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert negatives to positives ONLY for regular Sales\n",
    "df_clean.loc[\n",
    "    (df_clean['TransactionType'] == 'Sale') & \n",
    "    (df_clean['Quantity'] < 0), \n",
    "    'Quantity'\n",
    "] = df_clean['Quantity'].abs()  # Or: *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify this approach worked as intended, we check if there are any negative `Quantity` values remaining that are neither classified as \"Return\" nor \"SpecialCase\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Return or SpecialCase negative `Quantity` values: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Non Return or SpecialCase negative `Quantity` values: {df_clean[\n",
    "    (df_clean['Quantity'] < 0) & \n",
    "    (~df_clean['TransactionType'].isin(['Return', 'SpecialCase']))\n",
    "].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the result is 0, it confirms that all negative `Quantity` values have been correctly handled according to our classification. We can now proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizing and handling the negative values in `UnitPrice`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed earlier, only two transactions have negative `UnitPrice` values. Given their small number, we can inspect them directly as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299983</th>\n",
       "      <td>A563186</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>8/12/2011 14:51</td>\n",
       "      <td>-11062.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299984</th>\n",
       "      <td>A563187</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>8/12/2011 14:52</td>\n",
       "      <td>-11062.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode      Description  Quantity      InvoiceDate  \\\n",
       "299983   A563186         B  ADJUST BAD DEBT         1  8/12/2011 14:51   \n",
       "299984   A563187         B  ADJUST BAD DEBT         1  8/12/2011 14:52   \n",
       "\n",
       "        UnitPrice  CustomerID         Country TransactionType  \n",
       "299983  -11062.06         NaN  United Kingdom            Sale  \n",
       "299984  -11062.06         NaN  United Kingdom            Sale  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['UnitPrice'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since they are labeled as \"ADJUST BAD DEBT,\" these transactions appear to represent financial adjustments rather than product sales.\n",
    "\n",
    "As these records are valid, we will keep them in the dataset and classify them under \"SpecialCase\" in the `TransactionType` column while preserving their negative values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure \"ADJUST BAD DEBT\" transactions are marked as SpecialCase\n",
    "df_clean.loc[df_clean['Description'] == 'ADJUST BAD DEBT', 'TransactionType'] = 'SpecialCase'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from our initial exploration of `UnitPrice` shows that some transactions contain exceptionally high values. Upon further inspection, we found that several of these do not represent actual product sales but rather special cases, such as fees, postage, or adjustments.\n",
    "\n",
    "1. Identifying High `UnitPrice` Transactions\n",
    "To detect potential outliers, we examined the top transactions sorted by `UnitPrice`:\n",
    "\n",
    "- Initially, we used `df_clean.nlargest(10, 'UnitPrice')` to inspect the highest values.\n",
    "\n",
    "- Many high `UnitPrice` values corresponded to non-product transactions, which are **not currently classified as SpecialCases** (e.g., \"DOTCOM POSTAGE\", \"THROW AWAY\", \"MOULDY, THROWN AWAY.\").\n",
    "\n",
    "- To refine our analysis, we iteratively excluded known non-product descriptions and re-ran the analysis to identify remaining cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222681</th>\n",
       "      <td>C556445</td>\n",
       "      <td>M</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>6/10/2011 15:31</td>\n",
       "      <td>38970.00</td>\n",
       "      <td>15098.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524602</th>\n",
       "      <td>C580605</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/5/2011 11:36</td>\n",
       "      <td>17836.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43702</th>\n",
       "      <td>C540117</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/5/2011 9:55</td>\n",
       "      <td>16888.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43703</th>\n",
       "      <td>C540118</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/5/2011 9:57</td>\n",
       "      <td>16453.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>C537630</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:04</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15017</th>\n",
       "      <td>537632</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>1</td>\n",
       "      <td>12/7/2010 15:08</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16356</th>\n",
       "      <td>C537651</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:49</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16232</th>\n",
       "      <td>C537644</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:34</td>\n",
       "      <td>13474.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524601</th>\n",
       "      <td>C580604</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/5/2011 11:35</td>\n",
       "      <td>11586.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299982</th>\n",
       "      <td>A563185</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>8/12/2011 14:50</td>\n",
       "      <td>11062.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo  StockCode      Description  Quantity      InvoiceDate  \\\n",
       "222681   C556445          M           MANUAL        -1  6/10/2011 15:31   \n",
       "524602   C580605  AMAZONFEE       AMAZON FEE        -1  12/5/2011 11:36   \n",
       "43702    C540117  AMAZONFEE       AMAZON FEE        -1    1/5/2011 9:55   \n",
       "43703    C540118  AMAZONFEE       AMAZON FEE        -1    1/5/2011 9:57   \n",
       "15016    C537630  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:04   \n",
       "15017     537632  AMAZONFEE       AMAZON FEE         1  12/7/2010 15:08   \n",
       "16356    C537651  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:49   \n",
       "16232    C537644  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:34   \n",
       "524601   C580604  AMAZONFEE       AMAZON FEE        -1  12/5/2011 11:35   \n",
       "299982   A563185          B  ADJUST BAD DEBT         1  8/12/2011 14:50   \n",
       "\n",
       "        UnitPrice  CustomerID         Country TransactionType  \n",
       "222681   38970.00     15098.0  United Kingdom          Return  \n",
       "524602   17836.46         NaN  United Kingdom          Return  \n",
       "43702    16888.02         NaN  United Kingdom          Return  \n",
       "43703    16453.71         NaN  United Kingdom          Return  \n",
       "15016    13541.33         NaN  United Kingdom          Return  \n",
       "15017    13541.33         NaN  United Kingdom     SpecialCase  \n",
       "16356    13541.33         NaN  United Kingdom          Return  \n",
       "16232    13474.79         NaN  United Kingdom          Return  \n",
       "524601   11586.50         NaN  United Kingdom          Return  \n",
       "299982   11062.06         NaN  United Kingdom     SpecialCase  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.nlargest(10, 'UnitPrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Filtering Out Non-Product Cases\n",
    "We applied a filtering step to exclude descriptions that represent fees, adjustments, or other special cases, ensuring that we focus on actual product-related outliers. The filtered descriptions include:\n",
    "\n",
    "    \"AMAZON FEE\", \"MANUAL\", \"DOTCOM POSTAGE\", \"BANK CHARGES\", \"ADJUST BAD DEBT\", \"POSTAGE\", \"DISCOUNT\", \"CRUK COMMISSION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222680</th>\n",
       "      <td>556444</td>\n",
       "      <td>22502</td>\n",
       "      <td>PICNIC BASKET WICKER 60 PIECES</td>\n",
       "      <td>60</td>\n",
       "      <td>6/10/2011 15:28</td>\n",
       "      <td>649.5</td>\n",
       "      <td>15098.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222682</th>\n",
       "      <td>556446</td>\n",
       "      <td>22502</td>\n",
       "      <td>PICNIC BASKET WICKER 60 PIECES</td>\n",
       "      <td>1</td>\n",
       "      <td>6/10/2011 15:33</td>\n",
       "      <td>649.5</td>\n",
       "      <td>15098.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242589</th>\n",
       "      <td>C558359</td>\n",
       "      <td>S</td>\n",
       "      <td>SAMPLES</td>\n",
       "      <td>-1</td>\n",
       "      <td>6/28/2011 15:10</td>\n",
       "      <td>570.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>536835</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>12/2/2010 18:06</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13145.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32484</th>\n",
       "      <td>539080</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>12/16/2010 8:41</td>\n",
       "      <td>295.0</td>\n",
       "      <td>16607.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36165</th>\n",
       "      <td>C539438</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/17/2010 15:11</td>\n",
       "      <td>295.0</td>\n",
       "      <td>16607.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51636</th>\n",
       "      <td>540647</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>1/10/2011 14:57</td>\n",
       "      <td>295.0</td>\n",
       "      <td>17406.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82768</th>\n",
       "      <td>543253</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>2/4/2011 15:32</td>\n",
       "      <td>295.0</td>\n",
       "      <td>14842.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87141</th>\n",
       "      <td>C543632</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>-1</td>\n",
       "      <td>2/10/2011 16:22</td>\n",
       "      <td>295.0</td>\n",
       "      <td>14842.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118769</th>\n",
       "      <td>546480</td>\n",
       "      <td>22656</td>\n",
       "      <td>VINTAGE BLUE KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>3/14/2011 11:38</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13452.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                     Description  Quantity  \\\n",
       "222680    556444     22502  PICNIC BASKET WICKER 60 PIECES        60   \n",
       "222682    556446     22502  PICNIC BASKET WICKER 60 PIECES         1   \n",
       "242589   C558359         S                         SAMPLES        -1   \n",
       "4989      536835     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "32484     539080     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "36165    C539438     22655     VINTAGE RED KITCHEN CABINET        -1   \n",
       "51636     540647     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "82768     543253     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "87141    C543632     22655     VINTAGE RED KITCHEN CABINET        -1   \n",
       "118769    546480     22656    VINTAGE BLUE KITCHEN CABINET         1   \n",
       "\n",
       "             InvoiceDate  UnitPrice  CustomerID         Country  \\\n",
       "222680   6/10/2011 15:28      649.5     15098.0  United Kingdom   \n",
       "222682   6/10/2011 15:33      649.5     15098.0  United Kingdom   \n",
       "242589   6/28/2011 15:10      570.0         NaN  United Kingdom   \n",
       "4989     12/2/2010 18:06      295.0     13145.0  United Kingdom   \n",
       "32484    12/16/2010 8:41      295.0     16607.0  United Kingdom   \n",
       "36165   12/17/2010 15:11      295.0     16607.0  United Kingdom   \n",
       "51636    1/10/2011 14:57      295.0     17406.0  United Kingdom   \n",
       "82768     2/4/2011 15:32      295.0     14842.0  United Kingdom   \n",
       "87141    2/10/2011 16:22      295.0     14842.0  United Kingdom   \n",
       "118769   3/14/2011 11:38      295.0     13452.0  United Kingdom   \n",
       "\n",
       "       TransactionType  \n",
       "222680            Sale  \n",
       "222682            Sale  \n",
       "242589          Return  \n",
       "4989              Sale  \n",
       "32484             Sale  \n",
       "36165           Return  \n",
       "51636             Sale  \n",
       "82768             Sale  \n",
       "87141           Return  \n",
       "118769            Sale  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[~df_clean['Description'].isin(\n",
    "    [\"AMAZON FEE\", \"MANUAL\", 'DOTCOM POSTAGE', 'BANK CHARGES', 'ADJUST BAD DEBT', 'POSTAGE', 'DISCOUNT', 'CRUK COMMISSION' \n",
    "    ])].nlargest(10, 'UnitPrice')\n",
    "\n",
    "# 'DOTCOM POSTAGE', 'THROW AWAY', 'UNSALEABLE, DESTROYED.', 'MOULDY, THROWN AWAY.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the identified outliers, we expand the `special_case_list` to include these descriptions and reuse the `classify_transaction` function, ensuring they are correctly categorized in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the special_case_list with newly identified non-product descriptions\n",
    "special_case_list.extend([\n",
    "    \"DOTCOM POSTAGE\", \"THROW AWAY\", \"UNSALEABLE, DESTROYED.\", \"MOULDY, THROWN AWAY.\",\n",
    "    \"AMAZON FEE\", \"MANUAL\", \"BANK CHARGES\", \"ADJUST BAD DEBT\", \"POSTAGE\", \"DISCOUNT\", \"CRUK COMMISSION\"\n",
    "])\n",
    "\n",
    "# Reapplying the classification function to update TransactionType\n",
    "df_clean['TransactionType'] = list(map(classify_transaction, df_clean['InvoiceNo'], df_clean['Description']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can re-run the high `UnitPrice`analysis to confirm that all outliers are either properly classified or remain legitimate product sales.\n",
    "\n",
    "By implementing this refined approach, we ensure that outlier removal is not arbitrary but instead data-driven, focusing on legitimate product transactions while flagging non-product entries as SpecialCases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222681</th>\n",
       "      <td>C556445</td>\n",
       "      <td>M</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>6/10/2011 15:31</td>\n",
       "      <td>38970.00</td>\n",
       "      <td>15098.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524602</th>\n",
       "      <td>C580605</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/5/2011 11:36</td>\n",
       "      <td>17836.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43702</th>\n",
       "      <td>C540117</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/5/2011 9:55</td>\n",
       "      <td>16888.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43703</th>\n",
       "      <td>C540118</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/5/2011 9:57</td>\n",
       "      <td>16453.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>C537630</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:04</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15017</th>\n",
       "      <td>537632</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>1</td>\n",
       "      <td>12/7/2010 15:08</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16356</th>\n",
       "      <td>C537651</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:49</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16232</th>\n",
       "      <td>C537644</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/7/2010 15:34</td>\n",
       "      <td>13474.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524601</th>\n",
       "      <td>C580604</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>12/5/2011 11:35</td>\n",
       "      <td>11586.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299982</th>\n",
       "      <td>A563185</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>8/12/2011 14:50</td>\n",
       "      <td>11062.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo  StockCode      Description  Quantity      InvoiceDate  \\\n",
       "222681   C556445          M           MANUAL        -1  6/10/2011 15:31   \n",
       "524602   C580605  AMAZONFEE       AMAZON FEE        -1  12/5/2011 11:36   \n",
       "43702    C540117  AMAZONFEE       AMAZON FEE        -1    1/5/2011 9:55   \n",
       "43703    C540118  AMAZONFEE       AMAZON FEE        -1    1/5/2011 9:57   \n",
       "15016    C537630  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:04   \n",
       "15017     537632  AMAZONFEE       AMAZON FEE         1  12/7/2010 15:08   \n",
       "16356    C537651  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:49   \n",
       "16232    C537644  AMAZONFEE       AMAZON FEE        -1  12/7/2010 15:34   \n",
       "524601   C580604  AMAZONFEE       AMAZON FEE        -1  12/5/2011 11:35   \n",
       "299982   A563185          B  ADJUST BAD DEBT         1  8/12/2011 14:50   \n",
       "\n",
       "        UnitPrice  CustomerID         Country TransactionType  \n",
       "222681   38970.00     15098.0  United Kingdom          Return  \n",
       "524602   17836.46         NaN  United Kingdom          Return  \n",
       "43702    16888.02         NaN  United Kingdom          Return  \n",
       "43703    16453.71         NaN  United Kingdom          Return  \n",
       "15016    13541.33         NaN  United Kingdom          Return  \n",
       "15017    13541.33         NaN  United Kingdom     SpecialCase  \n",
       "16356    13541.33         NaN  United Kingdom          Return  \n",
       "16232    13474.79         NaN  United Kingdom          Return  \n",
       "524601   11586.50         NaN  United Kingdom          Return  \n",
       "299982   11062.06         NaN  United Kingdom     SpecialCase  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.nlargest(10, 'UnitPrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Explore basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into deeper analysis, it's essential to explore the dataset's basic statistics. This helps us understand key patterns, identify potential anomalies, and gain insights into the overall distribution of values.\n",
    "\n",
    "By summarizing numerical and categorical data, we can:\n",
    "- Detect **skewness or irregular distributions** in sales-related metrics.\n",
    "- Identify **unexpected values**, such as extremely high or low prices and quantities.\n",
    "- Assess **missing data patterns** that could impact further analysis.\n",
    "- Ensure the dataset is **ready for meaningful insights** without significant biases.\n",
    "\n",
    "Let's start by generating summary statistics and exploring key aspects of the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
