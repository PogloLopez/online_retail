{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Project: Online Retail EDA with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project explores an **online retail transactions dataset**, focusing on **data cleaning, exploratory data analysis (EDA), and deriving business insights**. The dataset contains information about customer purchases, including invoice details, product descriptions, quantities, prices, and customer IDs. \n",
    "\n",
    "\n",
    "### Objectives  \n",
    "- Perform **Exploratory Data Analysis (EDA)** to identify key trends.  \n",
    "- Analyze **sales performance, customer behavior, and popular products**.  \n",
    "- Provide **data-driven recommendations** to optimize online retail strategies.  \n",
    "\n",
    "\n",
    "### My Approach  \n",
    "To tackle this project, I’ll start by **ETL (Extract, Transform, Load)** to clean and prepare the dataset. Then, I’ll conduct in-depth analysis to identify key trends and insights like **busiest sales periods, top-selling products, and high-value customers**. Let's dive in!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this project, I'll be working with the **Online Retail** dataset, which contains transactional data from an online store between 2010 and 2011. The dataset is in a `.csv` file named **`online_retail.csv`**, and it includes details about purchases such as product descriptions, quantities, prices, timestamps, and customer IDs.  \n",
    "\n",
    "\n",
    "### Data Columns  \n",
    "The dataset consists of the following fields:  \n",
    "- **InvoiceNo** – Unique invoice number for each transaction.  \n",
    "- **StockCode** – Unique product identifier.  \n",
    "- **Description** – Product name/description.  \n",
    "- **Quantity** – Number of units purchased.  \n",
    "- **InvoiceDate** – Timestamp of the transaction.  \n",
    "- **UnitPrice** – Price per unit of the product.  \n",
    "- **CustomerID** – Unique identifier for each customer.  \n",
    "- **Country** – Country where the transaction took place.  \n",
    "\n",
    "\n",
    "Let's dive in and explore the dataset!  \n",
    "\n",
    "### My Approach\n",
    "\n",
    "To analyze this dataset effectively and derive meaningful insights, the workflow is divided into the following key stages:\n",
    "\n",
    "1. **Load the Data**  \n",
    "   Import the dataset into a Pandas DataFrame and inspect its structure and sample records.\n",
    "\n",
    "2. **Data Cleaning**  \n",
    "   Handle missing values, inconsistent entries, and remove irrelevant data to ensure accuracy.\n",
    "\n",
    "3. **Basic Statistics**  \n",
    "   Explore summary statistics to understand distributions and spot potential issues early on.\n",
    "\n",
    "4. **Feature Engineering**  \n",
    "   Create new variables such as `Revenue`, `InvoiceMonth`, and date-based features to enhance analysis.\n",
    "\n",
    "5. **Exploratory Data Analysis (EDA)**  \n",
    "   Investigate sales trends, customer behavior, product popularity, and country-wise performance.\n",
    "\n",
    "6. **Outlier Detection**  \n",
    "   Identify and manage anomalous transactions that could skew the results.\n",
    "\n",
    "7. **Visualizations**  \n",
    "   Use charts (e.g., histograms, time series, bar plots) to better communicate patterns and findings.\n",
    "\n",
    "8. **Insights and Recommendations**  \n",
    "   Summarize key takeaways and provide actionable recommendations based on the analysis.\n",
    "\n",
    "Let’s dive in and explore the dataset!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"source/online_retail.csv\", encoding=\"ISO-8859-1\")  # We use encoding to avoid UnicodeDecodeError (or encoding=\"Windows-1252\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore and familiarize with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>541909.000000</td>\n",
       "      <td>541909.000000</td>\n",
       "      <td>406829.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.552250</td>\n",
       "      <td>4.611114</td>\n",
       "      <td>15287.690570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>218.081158</td>\n",
       "      <td>96.759853</td>\n",
       "      <td>1713.600303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-80995.000000</td>\n",
       "      <td>-11062.060000</td>\n",
       "      <td>12346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>13953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>15152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>16791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80995.000000</td>\n",
       "      <td>38970.000000</td>\n",
       "      <td>18287.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Quantity      UnitPrice     CustomerID\n",
       "count  541909.000000  541909.000000  406829.000000\n",
       "mean        9.552250       4.611114   15287.690570\n",
       "std       218.081158      96.759853    1713.600303\n",
       "min    -80995.000000  -11062.060000   12346.000000\n",
       "25%         1.000000       1.250000   13953.000000\n",
       "50%         3.000000       2.080000   15152.000000\n",
       "75%        10.000000       4.130000   16791.000000\n",
       "max     80995.000000   38970.000000   18287.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the data types of each column and detected any missing (null) values, we have a clearer understanding of how to approach the ETL process.\n",
    "\n",
    "Before proceeding, let's create a copy of the dataframe to preserve the original data in its unaltered state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the copy created, we will begin by modifying the data types of specific columns.  \n",
    "In this case, we will convert the `Country`, `InvoiceNo`, and `StockCode` columns from the object type to the category type.  \n",
    "This transformation will optimize memory usage and improve performance when handling these columns in Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Country'] = df_clean['Country'].astype('category')\n",
    "df_clean['InvoiceNo'] = df_clean['InvoiceNo'].astype('category')\n",
    "df_clean['StockCode'] = df_clean['StockCode'].astype('category')\n",
    "\n",
    "# Ensure the data types where set correctly with: df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can also make sure that CustomerID is `int` instead of `float` to help Pandas process the information more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['CustomerID'] = df_clean['CustomerID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's turn `InvoiceDate` to **datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing `CustomerID` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains missing values in the `CustomerID` column, but these transactions are still valid purchases. Instead of dropping them or imputing arbitrary values (which could introduce bias), I will leave them as `NaN`.\n",
    "\n",
    " Why?\n",
    "- Removing these rows would result in **loss of actual transaction data**.\n",
    "- Imputing fake IDs would be **misleading**, as customer IDs are unique identifiers.\n",
    "- Pandas and Matplotlib **handle NaN values gracefully** in most operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing `Description` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains null values in the `Description` column. Since these rows cannot be dropped without losing valuable data, we impute the missing descriptions using the corresponding `StockCode` values (which are complete and unique).\n",
    "\n",
    "For that purpose, we follow this steps:\n",
    "1. **Create a mapping dictionary** where each `StockCode` points to its correct `Description` (using only rows with non-null descriptions)\n",
    "2. **Fill null values** by matching each missing `Description` with its `StockCode`'s known description\n",
    "\n",
    "**Key Note**: If a `StockCode` has no valid description in the dataset, its `NaN` values will remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Map StockCode to Description (drop duplicates to ensure 1:1 mapping)\n",
    "stock_to_desc = df_clean.dropna(subset=['Description']).drop_duplicates('StockCode').set_index('StockCode')['Description']\n",
    "\n",
    "# Step 2: Fill NaN Descriptions using the mapped StockCode values\n",
    "df_clean['Description'] = df_clean['Description'].fillna(df_clean['StockCode'].map(stock_to_desc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After handling the preliminary missing values in the `Description` column, it's important to verify if any null values still remain. We will perform this check to ensure that all missing descriptions have been properly handled before moving forward with further analysis.\n",
    "\n",
    "To do so, we'll check for any remaining nulls in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Description column null values: 1454\n",
      "Updated Description column null values: 112\n"
     ]
    }
   ],
   "source": [
    "# This will give us an updated count of the missing values in the 'Description' column\n",
    "print(f'Original Description column null values: {df['Description'].isna().sum()}')\n",
    "print(f'Updated Description column null values: {df_clean['Description'].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputing Remaining Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking for null values, we found that 112 missing descriptions remain out of the initial 1,454 null values. To ensure we don't lose valuable transaction data, we will impute these remaining null values with the placeholder `'Unknown'`. This decision allows us to retain all rows in the dataset while clearly marking the transactions with missing descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Description'] = df_clean['Description'].fillna('Unknown')\n",
    "\n",
    "# To make sure this worked as intended: print(df_clean['Description'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this, we preserve the full dataset while handling missing descriptions in a way that keeps the integrity of our analysis intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before removing duplicates, we need to ensure that all truly identical rows are recognized as such by Pandas. To achieve this, we will standardize string formatting to eliminate inconsistencies.\n",
    "\n",
    "We will focus on two key columns: `Description` and `Country`, as they contain string-type data.\n",
    "\n",
    "`Description`: We will remove leading, trailing, and extra in-between whitespaces and standardize all text to uppercase for consistency.\n",
    "\n",
    "`Country`: Similarly, we will trim unnecessary spaces and format country names in title case (first letter uppercase, the rest lowercase).\n",
    "\n",
    "These transformations will help ensure that duplicate records are correctly identified and handled in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Description: Remove leading/trailing spaces, handle in-between extra spaces, and standardize to lowercase\n",
    "df_clean['Description'] = df_clean['Description'].str.strip().str.replace(r'\\s+', ' ', regex=True).str.upper()\n",
    "\n",
    "# Clean Country: Remove leading/trailing spaces, handle in-between extra spaces, and title-case the country names\n",
    "df_clean['Country'] = df_clean['Country'].str.strip().str.replace(r'\\s+', ' ', regex=True).str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicated values can introduce bias and lead to incorrect insights, making it essential to handle them properly.\n",
    "\n",
    "To begin, we will check for duplicate records in the dataset. Since individual columns may contain duplicate values, our focus will be on identifying and removing rows where all columns are identical.\n",
    "\n",
    "For this, we will use Pandas' `.drop_duplicates()` method, which efficiently eliminates fully duplicated rows, ensuring data integrity for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 5268\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of duplicate rows: {df_clean.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicate rows\n",
    "df_clean = df_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating Negative Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of `df.describe()` in the *Load the Data* step, we identified negative values in the `Quantity` and `UnitPrice` columns. Since these values are not expected in a standard sales dataset, we will handle them systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10587\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Check for negative values in Quantity and UnitPrice\n",
    "print(df_clean[df_clean['Quantity'] < 0].shape[0])\n",
    "print(df_clean[df_clean['UnitPrice'] < 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of negative values in the `Quantity` column is significantly higher, we will address them first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizing the negative values in `Quantity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44205</th>\n",
       "      <td>C540158</td>\n",
       "      <td>22968</td>\n",
       "      <td>ROSE COTTAGE KEEPSAKE BOX</td>\n",
       "      <td>-2</td>\n",
       "      <td>2011-01-05 11:42:00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>12471</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188311</th>\n",
       "      <td>C553032</td>\n",
       "      <td>22148</td>\n",
       "      <td>EASTER CRAFT 4 CHICKS</td>\n",
       "      <td>-12</td>\n",
       "      <td>2011-05-12 19:44:00</td>\n",
       "      <td>1.95</td>\n",
       "      <td>13320</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393997</th>\n",
       "      <td>C570867</td>\n",
       "      <td>23256</td>\n",
       "      <td>CHILDRENS CUTLERY SPACEBOY</td>\n",
       "      <td>-4</td>\n",
       "      <td>2011-10-12 16:17:00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12607</td>\n",
       "      <td>Usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366477</th>\n",
       "      <td>568724</td>\n",
       "      <td>84816</td>\n",
       "      <td>DAMAGES</td>\n",
       "      <td>-21</td>\n",
       "      <td>2011-09-28 16:27:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70651</th>\n",
       "      <td>C542089</td>\n",
       "      <td>22300</td>\n",
       "      <td>COFFEE MUG DOG + BALL DESIGN</td>\n",
       "      <td>-2</td>\n",
       "      <td>2011-01-25 12:39:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>12681</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280898</th>\n",
       "      <td>C561510</td>\n",
       "      <td>22729</td>\n",
       "      <td>ALARM CLOCK BAKELIKE ORANGE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-07-27 14:51:00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>14534</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127557</th>\n",
       "      <td>C547232</td>\n",
       "      <td>85053</td>\n",
       "      <td>FRENCH ENAMEL CANDLEHOLDER</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-03-21 16:15:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>12994</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491733</th>\n",
       "      <td>C578073</td>\n",
       "      <td>M</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>-36</td>\n",
       "      <td>2011-11-22 16:02:00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>18139</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244401</th>\n",
       "      <td>C558522</td>\n",
       "      <td>22429</td>\n",
       "      <td>ENAMEL MEASURING JUG CREAM</td>\n",
       "      <td>-5</td>\n",
       "      <td>2011-06-30 10:33:00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>15932</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385925</th>\n",
       "      <td>C570221</td>\n",
       "      <td>22470</td>\n",
       "      <td>HEART OF WICKER LARGE</td>\n",
       "      <td>-33</td>\n",
       "      <td>2011-10-09 12:56:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>13113</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225294</th>\n",
       "      <td>C556647</td>\n",
       "      <td>21870</td>\n",
       "      <td>I CAN ONLY PLEASE ONE PERSON MUG</td>\n",
       "      <td>-12</td>\n",
       "      <td>2011-06-13 16:14:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>13012</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225430</th>\n",
       "      <td>C556673</td>\n",
       "      <td>22656</td>\n",
       "      <td>VINTAGE BLUE KITCHEN CABINET</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-06-13 17:08:00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>16949</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>C536548</td>\n",
       "      <td>22580</td>\n",
       "      <td>ADVENT CALENDAR GINGHAM SACK</td>\n",
       "      <td>-4</td>\n",
       "      <td>2010-12-01 14:33:00</td>\n",
       "      <td>5.95</td>\n",
       "      <td>12472</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293883</th>\n",
       "      <td>C562651</td>\n",
       "      <td>21991</td>\n",
       "      <td>BOHEMIAN COLLAGE STATIONERY SET</td>\n",
       "      <td>-12</td>\n",
       "      <td>2011-08-08 13:25:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>16951</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100710</th>\n",
       "      <td>C544831</td>\n",
       "      <td>22974</td>\n",
       "      <td>CHILDRENS DOLLY GIRL MUG</td>\n",
       "      <td>-2</td>\n",
       "      <td>2011-02-24 10:01:00</td>\n",
       "      <td>1.65</td>\n",
       "      <td>15146</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422617</th>\n",
       "      <td>C573098</td>\n",
       "      <td>23092</td>\n",
       "      <td>LARGE ANTIQUE WHITE PHOTO FRAME</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-10-27 14:45:00</td>\n",
       "      <td>7.90</td>\n",
       "      <td>15088</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340389</th>\n",
       "      <td>C566626</td>\n",
       "      <td>22461</td>\n",
       "      <td>SAVOY ART DECO CLOCK</td>\n",
       "      <td>-2</td>\n",
       "      <td>2011-09-14 10:07:00</td>\n",
       "      <td>3.95</td>\n",
       "      <td>15380</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537572</th>\n",
       "      <td>C581316</td>\n",
       "      <td>23174</td>\n",
       "      <td>REGENCY SUGAR BOWL GREEN</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-12-08 11:46:00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12523</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270323</th>\n",
       "      <td>C560561</td>\n",
       "      <td>22171</td>\n",
       "      <td>3 HOOK PHOTO SHELF ANTIQUE WHITE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-07-19 13:28:00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>17651</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215597</th>\n",
       "      <td>C555723</td>\n",
       "      <td>22171</td>\n",
       "      <td>3 HOOK PHOTO SHELF ANTIQUE WHITE</td>\n",
       "      <td>-2</td>\n",
       "      <td>2011-06-06 16:21:00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>15737</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                       Description  Quantity  \\\n",
       "44205    C540158     22968         ROSE COTTAGE KEEPSAKE BOX        -2   \n",
       "188311   C553032     22148             EASTER CRAFT 4 CHICKS       -12   \n",
       "393997   C570867     23256        CHILDRENS CUTLERY SPACEBOY        -4   \n",
       "366477    568724     84816                           DAMAGES       -21   \n",
       "70651    C542089     22300      COFFEE MUG DOG + BALL DESIGN        -2   \n",
       "280898   C561510     22729       ALARM CLOCK BAKELIKE ORANGE        -1   \n",
       "127557   C547232     85053        FRENCH ENAMEL CANDLEHOLDER        -1   \n",
       "491733   C578073         M                            MANUAL       -36   \n",
       "244401   C558522     22429        ENAMEL MEASURING JUG CREAM        -5   \n",
       "385925   C570221     22470             HEART OF WICKER LARGE       -33   \n",
       "225294   C556647     21870  I CAN ONLY PLEASE ONE PERSON MUG       -12   \n",
       "225430   C556673     22656      VINTAGE BLUE KITCHEN CABINET        -1   \n",
       "1986     C536548     22580      ADVENT CALENDAR GINGHAM SACK        -4   \n",
       "293883   C562651     21991   BOHEMIAN COLLAGE STATIONERY SET       -12   \n",
       "100710   C544831     22974          CHILDRENS DOLLY GIRL MUG        -2   \n",
       "422617   C573098     23092   LARGE ANTIQUE WHITE PHOTO FRAME        -1   \n",
       "340389   C566626     22461              SAVOY ART DECO CLOCK        -2   \n",
       "537572   C581316     23174          REGENCY SUGAR BOWL GREEN        -1   \n",
       "270323   C560561     22171  3 HOOK PHOTO SHELF ANTIQUE WHITE        -1   \n",
       "215597   C555723     22171  3 HOOK PHOTO SHELF ANTIQUE WHITE        -2   \n",
       "\n",
       "               InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "44205  2011-01-05 11:42:00       9.95       12471         Germany  \n",
       "188311 2011-05-12 19:44:00       1.95       13320  United Kingdom  \n",
       "393997 2011-10-12 16:17:00       4.15       12607             Usa  \n",
       "366477 2011-09-28 16:27:00       0.00        <NA>  United Kingdom  \n",
       "70651  2011-01-25 12:39:00       2.55       12681          France  \n",
       "280898 2011-07-27 14:51:00       3.75       14534  United Kingdom  \n",
       "127557 2011-03-21 16:15:00       2.10       12994  United Kingdom  \n",
       "491733 2011-11-22 16:02:00       0.56       18139  United Kingdom  \n",
       "244401 2011-06-30 10:33:00       4.25       15932  United Kingdom  \n",
       "385925 2011-10-09 12:56:00       2.55       13113  United Kingdom  \n",
       "225294 2011-06-13 16:14:00       1.25       13012  United Kingdom  \n",
       "225430 2011-06-13 17:08:00     125.00       16949  United Kingdom  \n",
       "1986   2010-12-01 14:33:00       5.95       12472         Germany  \n",
       "293883 2011-08-08 13:25:00       1.25       16951  United Kingdom  \n",
       "100710 2011-02-24 10:01:00       1.65       15146  United Kingdom  \n",
       "422617 2011-10-27 14:45:00       7.90       15088  United Kingdom  \n",
       "340389 2011-09-14 10:07:00       3.95       15380  United Kingdom  \n",
       "537572 2011-12-08 11:46:00       4.15       12523          France  \n",
       "270323 2011-07-19 13:28:00       8.50       17651  United Kingdom  \n",
       "215597 2011-06-06 16:21:00       8.50       15737  United Kingdom  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the negative values in Quantity and look for patterns\n",
    "df_clean[df_clean['Quantity'] < 0].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon examining the data, we can observe some patterns:  \n",
    "\n",
    "1. Most `InvoiceNo` values associated with negative quantities begin with \"C,\" which likely indicates a **credit transaction** (returns).  \n",
    "2. Some `Description` values suggest special cases, such as \"DAMAGED,\" \"DISCOUNT,\" or \"?\".  \n",
    "\n",
    "To better understand these cases, we will analyze how many unique `Description` values are associated with negative quantities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2471\n"
     ]
    }
   ],
   "source": [
    "negative_descriptions = df_clean[df_clean['Quantity'] < 0]['Description'].value_counts()\n",
    "print(negative_descriptions.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the large number of unique descriptions associated with negative quantities, we will focus on the most frequently occurring ones. This will help us identify common patterns and determine which descriptions may represent special cases that require specific handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description\n",
      "MANUAL                                 244\n",
      "REGENCY CAKESTAND 3 TIER               180\n",
      "POSTAGE                                126\n",
      "CHECK                                  123\n",
      "UNKNOWN                                 97\n",
      "JAM MAKING SET WITH JARS                87\n",
      "DISCOUNT                                77\n",
      "SET OF 3 CAKE TINS PANTRY DESIGN        75\n",
      "SAMPLES                                 61\n",
      "DAMAGED                                 57\n",
      "STRAWBERRY CERAMIC TRINKET BOX          54\n",
      "ROSES REGENCY TEACUP AND SAUCER         54\n",
      "RECIPE BOX PANTRY YELLOW DESIGN         47\n",
      "DAMAGES                                 46\n",
      "JUMBO BAG RED RETROSPOT                 44\n",
      "LUNCH BAG RED RETROSPOT                 44\n",
      "WOOD 2 DRAWER CABINET WHITE FINISH      43\n",
      "RED RETROSPOT CAKE STAND                42\n",
      "WHITE HANGING HEART T-LIGHT HOLDER      42\n",
      "GREEN REGENCY TEACUP AND SAUCER         42\n",
      "?                                       42\n",
      "SMALL GLASS HEART TRINKET POT           40\n",
      "SET OF 3 REGENCY CAKE TINS              37\n",
      "POPCORN HOLDER                          36\n",
      "PINK REGENCY TEACUP AND SAUCER          36\n",
      "SET OF TEA COFFEE SUGAR TINS PANTRY     35\n",
      "SILVER HANGING T-LIGHT HOLDER           35\n",
      "CLASSIC GLASS COOKIE JAR                34\n",
      "SET/5 RED RETROSPOT LID GLASS BOWLS     34\n",
      "AMAZON FEE                              32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(negative_descriptions.head(30))  # Show the top 30 most frequent negative descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the negative values in `Quantity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that some `Description` values represent regular products, while others indicate special cases (discounts, damaged products, or ambiguous values like \"?\"). We implement a unified classification system:\n",
    "\n",
    "1. Categorize All Transactions\n",
    "\n",
    "    Create a `TransactionType` column with three distinct labels:\n",
    "\n",
    "    * **Return:** Transactions where `InvoiceNo` starts with \"C\" (credit notes).\n",
    "    * **SpecialCase:** Transactions with descriptions matching predefined non-product terms (DISCOUNT, DAMAGED, SAMPLES, ?, etc.).\n",
    "    * **Sale:** All other regular transactions.\n",
    "\n",
    "2. Process Negative Quantities\n",
    "\n",
    "    * **Returns:** Keep negatives (valid refund records).\n",
    "    * **Special Cases:** Preserve original values (context-dependent).\n",
    "    * **Sales:** Convert negatives to positives (assumed data entry errors).\n",
    "\n",
    "**Note:** To distinguish legitimate negative quantities from data entry errors:\n",
    "\n",
    "* Identified the top 30 most frequent descriptions for negative quantities\n",
    "\n",
    "* Manually selected non-product terms (e.g., `DISCOUNT`, `DAMAGED`, `?`)\n",
    "\n",
    "Resulting in the curated `special_case_list` used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined list of special cases for descriptions\n",
    "special_case_list = [\n",
    "    'DISCOUNT', 'DAMAGED', 'DAMAGES', 'SAMPLES', 'CHECK', 'MANUAL', 'POSTAGE', \n",
    "    'UNKNOWN', '?', 'AMAZON FEE', 'DOTCOM POSTAGE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_transaction(invoice_no, description):\n",
    "    \"\"\"Classify transaction as 'Return', 'SpecialCase', or 'Sale'.\"\"\"\n",
    "    if str(invoice_no).startswith('C'):\n",
    "        return 'Return'\n",
    "    elif description in special_case_list:\n",
    "        return 'SpecialCase'\n",
    "    else:\n",
    "        return 'Sale'\n",
    "\n",
    "# Use .map() efficiently by applying it on a tuple of (InvoiceNo, Description)\n",
    "df_clean['TransactionType'] = list(map(classify_transaction, df_clean['InvoiceNo'], df_clean['Description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert negatives to positives ONLY for regular Sales\n",
    "df_clean.loc[\n",
    "    (df_clean['TransactionType'] == 'Sale') & \n",
    "    (df_clean['Quantity'] < 0), \n",
    "    'Quantity'\n",
    "] = df_clean['Quantity'].abs()  # Or: *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify this approach worked as intended, we check if there are any negative `Quantity` values remaining that are neither classified as \"Return\" nor \"SpecialCase\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Return or SpecialCase negative `Quantity` values: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Non Return or SpecialCase negative `Quantity` values: {df_clean[\n",
    "    (df_clean['Quantity'] < 0) & \n",
    "    (~df_clean['TransactionType'].isin(['Return', 'SpecialCase']))\n",
    "].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the result is 0, it confirms that all negative `Quantity` values have been correctly handled according to our classification. We can now proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizing and handling the negative values in `UnitPrice`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed earlier, only two transactions have negative `UnitPrice` values. Given their small number, we can inspect them directly as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299983</th>\n",
       "      <td>A563186</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-12 14:51:00</td>\n",
       "      <td>-11062.06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299984</th>\n",
       "      <td>A563187</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-12 14:52:00</td>\n",
       "      <td>-11062.06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode      Description  Quantity         InvoiceDate  \\\n",
       "299983   A563186         B  ADJUST BAD DEBT         1 2011-08-12 14:51:00   \n",
       "299984   A563187         B  ADJUST BAD DEBT         1 2011-08-12 14:52:00   \n",
       "\n",
       "        UnitPrice  CustomerID         Country TransactionType  \n",
       "299983  -11062.06        <NA>  United Kingdom            Sale  \n",
       "299984  -11062.06        <NA>  United Kingdom            Sale  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['UnitPrice'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since they are labeled as \"ADJUST BAD DEBT,\" these transactions appear to represent financial adjustments rather than product sales.\n",
    "\n",
    "As these records are valid, we will keep them in the dataset and classify them under \"SpecialCase\" in the `TransactionType` column while preserving their negative values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure \"ADJUST BAD DEBT\" transactions are marked as SpecialCase\n",
    "df_clean.loc[df_clean['Description'] == 'ADJUST BAD DEBT', 'TransactionType'] = 'SpecialCase'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from our initial exploration of `UnitPrice` shows that some transactions contain exceptionally high values. Upon further inspection, we found that several of these do not represent actual product sales but rather special cases, such as fees, postage, or adjustments.\n",
    "\n",
    "1. Identifying High `UnitPrice` Transactions\n",
    "To detect potential outliers, we examined the top transactions sorted by `UnitPrice`:\n",
    "\n",
    "- Initially, we used `df_clean.nlargest(10, 'UnitPrice')` to inspect the highest values.\n",
    "\n",
    "- Many high `UnitPrice` values corresponded to non-product transactions, which are **not currently classified as SpecialCases** (e.g., \"DOTCOM POSTAGE\", \"THROW AWAY\", \"MOULDY, THROWN AWAY.\").\n",
    "\n",
    "- To refine our analysis, we iteratively excluded known non-product descriptions and re-ran the analysis to identify remaining cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222681</th>\n",
       "      <td>C556445</td>\n",
       "      <td>M</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-06-10 15:31:00</td>\n",
       "      <td>38970.00</td>\n",
       "      <td>15098</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524602</th>\n",
       "      <td>C580605</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-12-05 11:36:00</td>\n",
       "      <td>17836.46</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43702</th>\n",
       "      <td>C540117</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-01-05 09:55:00</td>\n",
       "      <td>16888.02</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43703</th>\n",
       "      <td>C540118</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-01-05 09:57:00</td>\n",
       "      <td>16453.71</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>C537630</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-12-07 15:04:00</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15017</th>\n",
       "      <td>537632</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-07 15:08:00</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16356</th>\n",
       "      <td>C537651</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-12-07 15:49:00</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16232</th>\n",
       "      <td>C537644</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-12-07 15:34:00</td>\n",
       "      <td>13474.79</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524601</th>\n",
       "      <td>C580604</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-12-05 11:35:00</td>\n",
       "      <td>11586.50</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299982</th>\n",
       "      <td>A563185</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-12 14:50:00</td>\n",
       "      <td>11062.06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo  StockCode      Description  Quantity         InvoiceDate  \\\n",
       "222681   C556445          M           MANUAL        -1 2011-06-10 15:31:00   \n",
       "524602   C580605  AMAZONFEE       AMAZON FEE        -1 2011-12-05 11:36:00   \n",
       "43702    C540117  AMAZONFEE       AMAZON FEE        -1 2011-01-05 09:55:00   \n",
       "43703    C540118  AMAZONFEE       AMAZON FEE        -1 2011-01-05 09:57:00   \n",
       "15016    C537630  AMAZONFEE       AMAZON FEE        -1 2010-12-07 15:04:00   \n",
       "15017     537632  AMAZONFEE       AMAZON FEE         1 2010-12-07 15:08:00   \n",
       "16356    C537651  AMAZONFEE       AMAZON FEE        -1 2010-12-07 15:49:00   \n",
       "16232    C537644  AMAZONFEE       AMAZON FEE        -1 2010-12-07 15:34:00   \n",
       "524601   C580604  AMAZONFEE       AMAZON FEE        -1 2011-12-05 11:35:00   \n",
       "299982   A563185          B  ADJUST BAD DEBT         1 2011-08-12 14:50:00   \n",
       "\n",
       "        UnitPrice  CustomerID         Country TransactionType  \n",
       "222681   38970.00       15098  United Kingdom          Return  \n",
       "524602   17836.46        <NA>  United Kingdom          Return  \n",
       "43702    16888.02        <NA>  United Kingdom          Return  \n",
       "43703    16453.71        <NA>  United Kingdom          Return  \n",
       "15016    13541.33        <NA>  United Kingdom          Return  \n",
       "15017    13541.33        <NA>  United Kingdom     SpecialCase  \n",
       "16356    13541.33        <NA>  United Kingdom          Return  \n",
       "16232    13474.79        <NA>  United Kingdom          Return  \n",
       "524601   11586.50        <NA>  United Kingdom          Return  \n",
       "299982   11062.06        <NA>  United Kingdom     SpecialCase  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.nlargest(10, 'UnitPrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Filtering Out Non-Product Cases\n",
    "We applied a filtering step to exclude descriptions that represent fees, adjustments, or other special cases, ensuring that we focus on actual product-related outliers. The filtered descriptions include:\n",
    "\n",
    "    \"AMAZON FEE\", \"MANUAL\", \"DOTCOM POSTAGE\", \"BANK CHARGES\", \"ADJUST BAD DEBT\", \"POSTAGE\", \"DISCOUNT\", \"CRUK COMMISSION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222680</th>\n",
       "      <td>556444</td>\n",
       "      <td>22502</td>\n",
       "      <td>PICNIC BASKET WICKER 60 PIECES</td>\n",
       "      <td>60</td>\n",
       "      <td>2011-06-10 15:28:00</td>\n",
       "      <td>649.5</td>\n",
       "      <td>15098</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222682</th>\n",
       "      <td>556446</td>\n",
       "      <td>22502</td>\n",
       "      <td>PICNIC BASKET WICKER 60 PIECES</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-06-10 15:33:00</td>\n",
       "      <td>649.5</td>\n",
       "      <td>15098</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242589</th>\n",
       "      <td>C558359</td>\n",
       "      <td>S</td>\n",
       "      <td>SAMPLES</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-06-28 15:10:00</td>\n",
       "      <td>570.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>536835</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-02 18:06:00</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13145</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32484</th>\n",
       "      <td>539080</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-16 08:41:00</td>\n",
       "      <td>295.0</td>\n",
       "      <td>16607</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36165</th>\n",
       "      <td>C539438</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-12-17 15:11:00</td>\n",
       "      <td>295.0</td>\n",
       "      <td>16607</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51636</th>\n",
       "      <td>540647</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-10 14:57:00</td>\n",
       "      <td>295.0</td>\n",
       "      <td>17406</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82768</th>\n",
       "      <td>543253</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-02-04 15:32:00</td>\n",
       "      <td>295.0</td>\n",
       "      <td>14842</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87141</th>\n",
       "      <td>C543632</td>\n",
       "      <td>22655</td>\n",
       "      <td>VINTAGE RED KITCHEN CABINET</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-02-10 16:22:00</td>\n",
       "      <td>295.0</td>\n",
       "      <td>14842</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118769</th>\n",
       "      <td>546480</td>\n",
       "      <td>22656</td>\n",
       "      <td>VINTAGE BLUE KITCHEN CABINET</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-03-14 11:38:00</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13452</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                     Description  Quantity  \\\n",
       "222680    556444     22502  PICNIC BASKET WICKER 60 PIECES        60   \n",
       "222682    556446     22502  PICNIC BASKET WICKER 60 PIECES         1   \n",
       "242589   C558359         S                         SAMPLES        -1   \n",
       "4989      536835     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "32484     539080     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "36165    C539438     22655     VINTAGE RED KITCHEN CABINET        -1   \n",
       "51636     540647     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "82768     543253     22655     VINTAGE RED KITCHEN CABINET         1   \n",
       "87141    C543632     22655     VINTAGE RED KITCHEN CABINET        -1   \n",
       "118769    546480     22656    VINTAGE BLUE KITCHEN CABINET         1   \n",
       "\n",
       "               InvoiceDate  UnitPrice  CustomerID         Country  \\\n",
       "222680 2011-06-10 15:28:00      649.5       15098  United Kingdom   \n",
       "222682 2011-06-10 15:33:00      649.5       15098  United Kingdom   \n",
       "242589 2011-06-28 15:10:00      570.0        <NA>  United Kingdom   \n",
       "4989   2010-12-02 18:06:00      295.0       13145  United Kingdom   \n",
       "32484  2010-12-16 08:41:00      295.0       16607  United Kingdom   \n",
       "36165  2010-12-17 15:11:00      295.0       16607  United Kingdom   \n",
       "51636  2011-01-10 14:57:00      295.0       17406  United Kingdom   \n",
       "82768  2011-02-04 15:32:00      295.0       14842  United Kingdom   \n",
       "87141  2011-02-10 16:22:00      295.0       14842  United Kingdom   \n",
       "118769 2011-03-14 11:38:00      295.0       13452  United Kingdom   \n",
       "\n",
       "       TransactionType  \n",
       "222680            Sale  \n",
       "222682            Sale  \n",
       "242589          Return  \n",
       "4989              Sale  \n",
       "32484             Sale  \n",
       "36165           Return  \n",
       "51636             Sale  \n",
       "82768             Sale  \n",
       "87141           Return  \n",
       "118769            Sale  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[~df_clean['Description'].isin(\n",
    "    [\"AMAZON FEE\", \"MANUAL\", 'DOTCOM POSTAGE', 'BANK CHARGES', 'ADJUST BAD DEBT', 'POSTAGE', 'DISCOUNT', 'CRUK COMMISSION' \n",
    "    ])].nlargest(10, 'UnitPrice')\n",
    "\n",
    "# 'DOTCOM POSTAGE', 'THROW AWAY', 'UNSALEABLE, DESTROYED.', 'MOULDY, THROWN AWAY.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the identified outliers, we expand the `special_case_list` to include these descriptions and reuse the `classify_transaction` function, ensuring they are correctly categorized in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the special_case_list with newly identified non-product descriptions\n",
    "special_case_list.extend([\n",
    "    \"DOTCOM POSTAGE\", \"THROW AWAY\", \"UNSALEABLE, DESTROYED.\", \"MOULDY, THROWN AWAY.\",\n",
    "    \"AMAZON FEE\", \"MANUAL\", \"BANK CHARGES\", \"ADJUST BAD DEBT\", \"POSTAGE\", \"DISCOUNT\", \"CRUK COMMISSION\"\n",
    "])\n",
    "\n",
    "# Reapplying the classification function to update TransactionType\n",
    "df_clean['TransactionType'] = list(map(classify_transaction, df_clean['InvoiceNo'], df_clean['Description']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can re-run the high `UnitPrice`analysis to confirm that all outliers are either properly classified or remain legitimate product sales.\n",
    "\n",
    "By implementing this refined approach, we ensure that outlier removal is not arbitrary but instead data-driven, focusing on legitimate product transactions while flagging non-product entries as SpecialCases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TransactionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222681</th>\n",
       "      <td>C556445</td>\n",
       "      <td>M</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-06-10 15:31:00</td>\n",
       "      <td>38970.00</td>\n",
       "      <td>15098</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524602</th>\n",
       "      <td>C580605</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-12-05 11:36:00</td>\n",
       "      <td>17836.46</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43702</th>\n",
       "      <td>C540117</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-01-05 09:55:00</td>\n",
       "      <td>16888.02</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43703</th>\n",
       "      <td>C540118</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-01-05 09:57:00</td>\n",
       "      <td>16453.71</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>C537630</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-12-07 15:04:00</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15017</th>\n",
       "      <td>537632</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-07 15:08:00</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16356</th>\n",
       "      <td>C537651</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-12-07 15:49:00</td>\n",
       "      <td>13541.33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16232</th>\n",
       "      <td>C537644</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-12-07 15:34:00</td>\n",
       "      <td>13474.79</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524601</th>\n",
       "      <td>C580604</td>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "      <td>-1</td>\n",
       "      <td>2011-12-05 11:35:00</td>\n",
       "      <td>11586.50</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299982</th>\n",
       "      <td>A563185</td>\n",
       "      <td>B</td>\n",
       "      <td>ADJUST BAD DEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-12 14:50:00</td>\n",
       "      <td>11062.06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>SpecialCase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo  StockCode      Description  Quantity         InvoiceDate  \\\n",
       "222681   C556445          M           MANUAL        -1 2011-06-10 15:31:00   \n",
       "524602   C580605  AMAZONFEE       AMAZON FEE        -1 2011-12-05 11:36:00   \n",
       "43702    C540117  AMAZONFEE       AMAZON FEE        -1 2011-01-05 09:55:00   \n",
       "43703    C540118  AMAZONFEE       AMAZON FEE        -1 2011-01-05 09:57:00   \n",
       "15016    C537630  AMAZONFEE       AMAZON FEE        -1 2010-12-07 15:04:00   \n",
       "15017     537632  AMAZONFEE       AMAZON FEE         1 2010-12-07 15:08:00   \n",
       "16356    C537651  AMAZONFEE       AMAZON FEE        -1 2010-12-07 15:49:00   \n",
       "16232    C537644  AMAZONFEE       AMAZON FEE        -1 2010-12-07 15:34:00   \n",
       "524601   C580604  AMAZONFEE       AMAZON FEE        -1 2011-12-05 11:35:00   \n",
       "299982   A563185          B  ADJUST BAD DEBT         1 2011-08-12 14:50:00   \n",
       "\n",
       "        UnitPrice  CustomerID         Country TransactionType  \n",
       "222681   38970.00       15098  United Kingdom          Return  \n",
       "524602   17836.46        <NA>  United Kingdom          Return  \n",
       "43702    16888.02        <NA>  United Kingdom          Return  \n",
       "43703    16453.71        <NA>  United Kingdom          Return  \n",
       "15016    13541.33        <NA>  United Kingdom          Return  \n",
       "15017    13541.33        <NA>  United Kingdom     SpecialCase  \n",
       "16356    13541.33        <NA>  United Kingdom          Return  \n",
       "16232    13474.79        <NA>  United Kingdom          Return  \n",
       "524601   11586.50        <NA>  United Kingdom          Return  \n",
       "299982   11062.06        <NA>  United Kingdom     SpecialCase  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.nlargest(10, 'UnitPrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the dataset, we proceed to explore its basic statistics. This initial analysis provides a foundation for understanding the data’s structure, identifying early patterns, and evaluating potential anomalies or irregularities. It sets the stage for more advanced analytical steps by offering a general snapshot of the dataset’s composition.\n",
    "\n",
    "We begin by generating summary statistics and exploring key aspects of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 536641 entries, 0 to 541908\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   InvoiceNo        536641 non-null  category      \n",
      " 1   StockCode        536641 non-null  category      \n",
      " 2   Description      536641 non-null  object        \n",
      " 3   Quantity         536641 non-null  int64         \n",
      " 4   InvoiceDate      536641 non-null  datetime64[ns]\n",
      " 5   UnitPrice        536641 non-null  float64       \n",
      " 6   CustomerID       401604 non-null  Int64         \n",
      " 7   Country          536641 non-null  object        \n",
      " 8   TransactionType  536641 non-null  object        \n",
      "dtypes: Int64(1), category(2), datetime64[ns](1), float64(1), int64(1), object(3)\n",
      "memory usage: 52.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Observations:**\n",
    "\n",
    "- **Rows**: 536,641 transactions\n",
    "- **Columns**: 9\n",
    "- Missing Values: Most columns are complete, except for CustomerID, which is missing in approximately 25% of the records\n",
    "- **Derived Column**: A new column, `TransactionType`, classifies each row as a `Sale`, `Return`, or `SpecialCase` based on invoice patterns and product descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionType\n",
       "Sale           0.977879\n",
       "Return         0.017239\n",
       "SpecialCase    0.004882\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['TransactionType'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of transactions are regular **Sales**, followed by a smaller proportion of **Returns** and **Special Cases**, as expected based on our previous classification process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of each transaction type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having all transactions categorized under `TransactionType`, we can now analyze each group independently without conflating their behaviors. This allows for more accurate insights and better handling of specific cases.\n",
    "\n",
    "To begin, we use the `.describe()` method to generate summary statistics for each transaction type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>524770.000000</td>\n",
       "      <td>524770</td>\n",
       "      <td>524770.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.987383</td>\n",
       "      <td>2011-07-04 13:00:30.277493504</td>\n",
       "      <td>3.274727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2011-03-28 11:51:00</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2011-07-19 17:17:00</td>\n",
       "      <td>2.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>2011-10-19 10:59:00</td>\n",
       "      <td>4.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80995.000000</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>649.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>159.878853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.460465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Quantity                    InvoiceDate      UnitPrice\n",
       "count  524770.000000                         524770  524770.000000\n",
       "mean       10.987383  2011-07-04 13:00:30.277493504       3.274727\n",
       "min         1.000000            2010-12-01 08:26:00       0.000000\n",
       "25%         1.000000            2011-03-28 11:51:00       1.250000\n",
       "50%         4.000000            2011-07-19 17:17:00       2.080000\n",
       "75%        12.000000            2011-10-19 10:59:00       4.130000\n",
       "max     80995.000000            2011-12-09 12:50:00     649.500000\n",
       "std       159.878853                            NaN       4.460465"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['TransactionType'] == 'Sale'].drop(columns=['CustomerID']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9251.000000</td>\n",
       "      <td>9251</td>\n",
       "      <td>9251.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-29.787050</td>\n",
       "      <td>2011-06-26 07:06:45.231866880</td>\n",
       "      <td>48.570430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-80995.000000</td>\n",
       "      <td>2010-12-01 09:41:00</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.000000</td>\n",
       "      <td>2011-03-21 16:26:00</td>\n",
       "      <td>1.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>2011-07-08 13:04:00</td>\n",
       "      <td>2.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2011-10-06 20:36:00</td>\n",
       "      <td>5.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2011-12-09 11:58:00</td>\n",
       "      <td>38970.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1147.997592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>667.926393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Quantity                    InvoiceDate     UnitPrice\n",
       "count   9251.000000                           9251   9251.000000\n",
       "mean     -29.787050  2011-06-26 07:06:45.231866880     48.570430\n",
       "min   -80995.000000            2010-12-01 09:41:00      0.010000\n",
       "25%       -6.000000            2011-03-21 16:26:00      1.450000\n",
       "50%       -2.000000            2011-07-08 13:04:00      2.950000\n",
       "75%       -1.000000            2011-10-06 20:36:00      5.950000\n",
       "max       -1.000000            2011-12-09 11:58:00  38970.000000\n",
       "std     1147.997592                            NaN    667.926393"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['TransactionType'] == 'Return'].drop(columns=['CustomerID']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2620.000000</td>\n",
       "      <td>2620</td>\n",
       "      <td>2620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.115649</td>\n",
       "      <td>2011-06-29 00:50:42.847328256</td>\n",
       "      <td>121.476855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3000.000000</td>\n",
       "      <td>2010-12-01 08:45:00</td>\n",
       "      <td>-11062.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2011-03-25 14:14:15</td>\n",
       "      <td>2.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2011-07-05 17:01:00</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2011-10-13 16:19:45</td>\n",
       "      <td>118.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5368.000000</td>\n",
       "      <td>2011-12-09 12:16:00</td>\n",
       "      <td>13541.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>232.965881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>580.267542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Quantity                    InvoiceDate     UnitPrice\n",
       "count  2620.000000                           2620   2620.000000\n",
       "mean      4.115649  2011-06-29 00:50:42.847328256    121.476855\n",
       "min   -3000.000000            2010-12-01 08:45:00 -11062.060000\n",
       "25%       1.000000            2011-03-25 14:14:15      2.950000\n",
       "50%       1.000000            2011-07-05 17:01:00     18.000000\n",
       "75%       2.000000            2011-10-13 16:19:45    118.342500\n",
       "max    5368.000000            2011-12-09 12:16:00  13541.330000\n",
       "std     232.965881                            NaN    580.267542"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['TransactionType'] == 'SpecialCase'].drop(columns=['CustomerID']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "\n",
    "- **Returns** correctly reflect negative quantities, consistent with refund transactions.\n",
    "- **Special Cases** exhibit high variability in both `Quantity` and `UnitPrice`, supporting their exclusion from regular sales analysis.\n",
    "- **Sales** now contain only positive quantities and show a reasonable distribution of unit prices, indicating reliable data for core business analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we enrich our dataset by creating new, meaningful features that will support future exploratory analysis and help uncover deeper insights.\n",
    "\n",
    "The main goals of this step are to:\n",
    "\n",
    "- Create a Revenue column to measure transaction value.\n",
    "- Extract time-based features from the invoice date to enable seasonality and behavior analysis.\n",
    "- Engineer RFM (Recency, Frequency, Monetary) features to evaluate customer behavior and segment them based on purchasing patterns.\n",
    "\n",
    "These engineered features will serve as a strong foundation for both exploratory data analysis (EDA) and potential modeling in future steps.\n",
    "\n",
    "We begin by creating a `Revenue` column for each transaction by multiplying `Quantity` by `UnitPrice`. This serves as the foundation for later customer value analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Revenue'] = df_clean['Quantity'] * df_clean['UnitPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable temporal analysis, we extract multiple date and time features from the `InvoiceDate` column. These will be useful for analyzing seasonality, trends, and customer behavior over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['InvoiceYear'] = df_clean['InvoiceDate'].dt.year\n",
    "df_clean['InvoiceMonth'] = df_clean['InvoiceDate'].dt.month\n",
    "df_clean['InvoiceDay'] = df_clean['InvoiceDate'].dt.day\n",
    "df_clean['InvoiceHour'] = df_clean['InvoiceDate'].dt.hour\n",
    "df_clean['InvoiceWeekday'] = df_clean['InvoiceDate'].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM analysis feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enhance our understanding of customer behavior, we’ll perform a **RFM (Recency, Frequency, Monetary) analysis** — a well-established method for customer segmentation based on purchasing patterns.\n",
    "\n",
    "Since RFM relies on the `CustomerID` column, and we intentionally retained null values in our main dataset (`df_clean`) to avoid bias in other analyses, we’ll work with a filtered copy. This new DataFrame, `notnull_customer_df`, includes only sales transactions with valid `CustomerID` values to ensure accurate segmentation.\n",
    "\n",
    "Additionally, RFM analysis requires a reference point in time to calculate `Recency`. We'll define this reference date as one day after the most recent InvoiceDate in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the dataset to include only regular sales (`TransactionType == 'Sale'`) and transactions with known `CustomerID`. This ensures a reliable and unbiased base for calculating RFM metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "notnull_customer_df = df_clean[\n",
    "    (df_clean['TransactionType'] == 'Sale') &\n",
    "    (df_clean['CustomerID'].notnull())\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the **Recency** metric (how recently each customer purchased), we define a `reference_date` as one day after the most recent invoice in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Select the reference date for RFM analysis\n",
    "reference_date = notnull_customer_df['InvoiceDate'].max() + pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate RFM metrics, we group transactions by CustomerID and compute the three core RFM metrics:\n",
    "\n",
    "- **Recency**: Days since last purchase\n",
    "- **Frequency**: Number of unique invoices (transactions)\n",
    "- **Monetary**: Total revenue generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group by CustomerID and aggregate Recency, Frequency, Monetary\n",
    "df_rfm = notnull_customer_df.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (reference_date - x.max()).days,            # Recency\n",
    "    'InvoiceNo': 'nunique',                                              # Frequency\n",
    "    'UnitPrice': 'sum'                                                   # Temporary, we'll correct this below\n",
    "}).rename(columns={\n",
    "    'InvoiceDate': 'Recency',\n",
    "    'InvoiceNo': 'Frequency',\n",
    "})\n",
    "\n",
    "# Replace the placeholder UnitPrice sum with actual customer revenue using the Revenue column\n",
    "df_rfm['Monetary'] =  notnull_customer_df.groupby('CustomerID')['Revenue'].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review summary statistics for the RFM features to understand their ranges, distributions, and central tendencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Monetary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4335.000000</td>\n",
       "      <td>4335.000000</td>\n",
       "      <td>4335.000000</td>\n",
       "      <td>4335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>92.684890</td>\n",
       "      <td>4.246367</td>\n",
       "      <td>260.894753</td>\n",
       "      <td>2017.050437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>100.172622</td>\n",
       "      <td>7.643880</td>\n",
       "      <td>697.201332</td>\n",
       "      <td>8919.387033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.850000</td>\n",
       "      <td>304.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.950000</td>\n",
       "      <td>663.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>143.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>277.860000</td>\n",
       "      <td>1631.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>374.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>22776.010000</td>\n",
       "      <td>279138.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Recency    Frequency     UnitPrice       Monetary\n",
       "count  4335.000000  4335.000000   4335.000000    4335.000000\n",
       "mean     92.684890     4.246367    260.894753    2017.050437\n",
       "std     100.172622     7.643880    697.201332    8919.387033\n",
       "min       1.000000     1.000000      0.000000       0.000000\n",
       "25%      18.000000     1.000000     48.850000     304.250000\n",
       "50%      51.000000     2.000000    120.950000     663.610000\n",
       "75%     143.000000     5.000000    277.860000    1631.475000\n",
       "max     374.000000   206.000000  22776.010000  279138.020000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rfm.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
